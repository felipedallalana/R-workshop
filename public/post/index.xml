<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on APS - WORKSHOP</title>
    <link>/post/</link>
    <description>Recent content in Posts on APS - WORKSHOP</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 01 Aug 2019 21:09:10 -0500</lastBuildDate>
    
	    <atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Introduction to R</title>
      <link>/post/introduction_mcroberts_and_esker/</link>
      <pubDate>Thu, 01 Aug 2019 21:09:10 -0500</pubDate>
      
      <guid>/post/introduction_mcroberts_and_esker/</guid>
      <description>


&lt;p&gt;This introduction were developed by Neil McRoberts and Paul Esker, and presented on APS 2015 and ISPP 2018 Workshops.&lt;/p&gt;
&lt;div id=&#34;basic-introduction-to-r.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;em&gt;&lt;strong&gt;Basic introduction to R.&lt;/strong&gt;&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;Some online resouces:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.introductoryr.co.uk/R_Resources_for_Beginners.html&#34; class=&#34;uri&#34;&gt;http://www.introductoryr.co.uk/R_Resources_for_Beginners.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.statmethods.net/index.html&#34; class=&#34;uri&#34;&gt;http://www.statmethods.net/index.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.ats.ucla.edu/stat/r/&#34; class=&#34;uri&#34;&gt;http://www.ats.ucla.edu/stat/r/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.r-tutor.com/r-introduction&#34; class=&#34;uri&#34;&gt;http://www.r-tutor.com/r-introduction&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;####&lt;strong&gt;R as a calculator&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;R has basics operations to add, subtract, mulitply and divide. Also, R defines certain caluclations, such as pi, based on alpha-numeric nomenclature.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;7+2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 9&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;5/2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2.5&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;6*9&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 54&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;1000-89&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 911&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;12/pi&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3.819719&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;####&lt;strong&gt;Creating Objects&lt;/strong&gt;
This first step enables us to start creating data vectors, or more simply a list of information of interest.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;X &amp;lt;- 43 
X&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 43&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- 23 
x&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 23&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ls() ### To see that we have both &amp;quot;X&amp;quot; and &amp;quot;x&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;x&amp;quot; &amp;quot;X&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Y &amp;lt;- c(3,2,6) 
Y&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3 2 6&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Y2 &amp;lt;- c(3,X,x)
Y2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  3 43 23&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Y3 &amp;lt;- c(Y,Y2)
Y3 &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  3  2  6  3 43 23&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;####&lt;strong&gt;Sequences of numbers&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The following code illustrates different examples of how one can define a list (vector) of information.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Set1 &amp;lt;- c(1,2,3,4,5,6,7,8,9)
Set2 &amp;lt;- 1:9
Set3 &amp;lt;- seq(1,10)
Set4 &amp;lt;- seq(1,10,0.5)
### Set4 comes from the following code, more formally defined: seq(from=1,to=10,by=0.5)
Set4&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  1.0  1.5  2.0  2.5  3.0  3.5  4.0  4.5  5.0  5.5  6.0  6.5  7.0  7.5
## [15]  8.0  8.5  9.0  9.5 10.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Set1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1 2 3 4 5 6 7 8 9&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Set2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1 2 3 4 5 6 7 8 9&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Set3&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  1  2  3  4  5  6  7  8  9 10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;####&lt;strong&gt;Vectors of data and information&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;X &amp;lt;- c(4,2,7)
X2 &amp;lt;- seq(3,6)

# Combining vectors of information: cbind (column) or rbind (row)
X &amp;lt;- c(1,2,3)
Y &amp;lt;- c(7,8,9)
Z &amp;lt;- cbind(X,Y)
Z&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      X Y
## [1,] 1 7
## [2,] 2 8
## [3,] 3 9&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Z2 &amp;lt;- rbind(X,Y)
Z2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   [,1] [,2] [,3]
## X    1    2    3
## Y    7    8    9&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Understanding how R interprets different types of vectors
example=c(1,2,3,4,5,6,7,8,9,10)
class(example) #numeric&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;new.example=c(&amp;quot;A&amp;quot;,&amp;quot;B&amp;quot;,&amp;quot;C&amp;quot;,&amp;quot;D&amp;quot;)
class(new.example) #character&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;####&lt;strong&gt;Matrices and arrays&lt;/strong&gt;
Matrices and arrays are ways to organize data into a collection of data entries (rows and columns, along with subgroups of information).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Matrix
Mat1 &amp;lt;- matrix(1,ncol=3,nrow=4) #Matrix of 1&amp;#39;s, with 4 rows and 3 columns
Mat1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2] [,3]
## [1,]    1    1    1
## [2,]    1    1    1
## [3,]    1    1    1
## [4,]    1    1    1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Let&amp;#39;s use X and Y previously defined to make a matrix of data
Z &amp;lt;- c(X,Y)
Z&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1 2 3 7 8 9&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Mat2 &amp;lt;- matrix(Z,ncol=2,byrow=F)
Mat2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2]
## [1,]    1    7
## [2,]    2    8
## [3,]    3    9&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(Mat2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;matrix&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;####&lt;strong&gt;Creating a matrix using “plant pathological” data&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;disease=matrix(c(1,1,1,1,2,2,2,2,5,15,35,55,11,30,61,75),ncol=2,nrow=8)
colnames(disease)=c(&amp;quot;Trt&amp;quot;,&amp;quot;Sev&amp;quot;)
disease&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      Trt Sev
## [1,]   1   5
## [2,]   1  15
## [3,]   1  35
## [4,]   1  55
## [5,]   2  11
## [6,]   2  30
## [7,]   2  61
## [8,]   2  75&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;is.matrix(disease)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Evaluating a vector - basic methods&lt;/strong&gt;
Basic calculations like:
mean()
median()
var()
summary() - Notice here we are provided with a basic 5 (6) number summary.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;X &amp;lt;- rnorm(20,mean=5,sd=2) 
#rnorm() generates a random vector of 20 observations, each from a mean=5 with a standard deviation of 2

length(X)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 20&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(X)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 5.315794&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;median(X)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 5.262273&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;var(X)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3.220747&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(X)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   2.010   4.301   5.262   5.316   6.140   9.965&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Another example
Rendimiento&amp;lt;-c(4.2,4.94,4.45,4.36,3.5,4.17,5.4,4.55,5.75,5.15,4.4,3.9,2.82,3.14,3.8,3.74,4.43,2.92,4.82,3.9,4.5,4.57,5.32,4.35)
mean(Rendimiento)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 4.295&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;var(Rendimiento)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.5642&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sd(Rendimiento)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.7511325&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;length(Rendimiento)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 24&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(Rendimiento)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   2.820   3.875   4.380   4.295   4.633   5.750&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;####&lt;strong&gt;Matrix calculations&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The same functions can be applied to matrices, but it is important to understand that with some of the functions, for example var(), the calculation is based on the columns and comparisons (covariance as one idea) between them.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Mat2 &amp;lt;- matrix(Z,ncol=2,byrow=F)
Mat2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2]
## [1,]    1    7
## [2,]    2    8
## [3,]    3    9&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;length(Mat2) # Less straightforward in 2 dimensions&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 6&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(Mat2) # Rows and columns&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3 2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(Mat2) # Can you see how this was calculated?&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 5&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;median(Mat2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 5&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;var(Mat2) # Notice now we are working in 2 dimensions for this calculation - variances-covariances-correlations&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2]
## [1,]    1    1
## [2,]    1    1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(Mat2) # By column&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        V1            V2     
##  Min.   :1.0   Min.   :7.0  
##  1st Qu.:1.5   1st Qu.:7.5  
##  Median :2.0   Median :8.0  
##  Mean   :2.0   Mean   :8.0  
##  3rd Qu.:2.5   3rd Qu.:8.5  
##  Max.   :3.0   Max.   :9.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Another example (much larger)
Mat3 &amp;lt;- matrix(seq(1,50),ncol=2,byrow=T)
Mat3&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       [,1] [,2]
##  [1,]    1    2
##  [2,]    3    4
##  [3,]    5    6
##  [4,]    7    8
##  [5,]    9   10
##  [6,]   11   12
##  [7,]   13   14
##  [8,]   15   16
##  [9,]   17   18
## [10,]   19   20
## [11,]   21   22
## [12,]   23   24
## [13,]   25   26
## [14,]   27   28
## [15,]   29   30
## [16,]   31   32
## [17,]   33   34
## [18,]   35   36
## [19,]   37   38
## [20,]   39   40
## [21,]   41   42
## [22,]   43   44
## [23,]   45   46
## [24,]   47   48
## [25,]   49   50&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(Mat3) # gives the first 6 rows by default&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2]
## [1,]    1    2
## [2,]    3    4
## [3,]    5    6
## [4,]    7    8
## [5,]    9   10
## [6,]   11   12&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(Mat3, n=10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       [,1] [,2]
##  [1,]    1    2
##  [2,]    3    4
##  [3,]    5    6
##  [4,]    7    8
##  [5,]    9   10
##  [6,]   11   12
##  [7,]   13   14
##  [8,]   15   16
##  [9,]   17   18
## [10,]   19   20&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tail(Mat3) # gives the last 6 rows by default&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       [,1] [,2]
## [20,]   39   40
## [21,]   41   42
## [22,]   43   44
## [23,]   45   46
## [24,]   47   48
## [25,]   49   50&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;####&lt;strong&gt;Working with matrices - operations&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Mat2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2]
## [1,]    1    7
## [2,]    2    8
## [3,]    3    9&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;5*Mat2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2]
## [1,]    5   35
## [2,]   10   40
## [3,]   15   45&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;5+Mat2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2]
## [1,]    6   12
## [2,]    7   13
## [3,]    8   14&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Mat2[,1] &amp;lt;- Mat2[,1] + 100 # Changing just the first column of Mat2
Mat2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2]
## [1,]  101    7
## [2,]  102    8
## [3,]  103    9&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;####&lt;strong&gt;Data frames&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;More commonly, we will employ a database created in another program, for example Excel. In this case, we are working with a data frame that has mixed information, such as alpha-numerica, data, etc. Nonetheless, we can handle this information in R like the previously examples. In this part, we will take a matrix and turn this into a data.frame, but after, we will see generically, examples of introducing the data from file.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;disease &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      Trt Sev
## [1,]   1   5
## [2,]   1  15
## [3,]   1  35
## [4,]   1  55
## [5,]   2  11
## [6,]   2  30
## [7,]   2  61
## [8,]   2  75&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;GreatData &amp;lt;- data.frame(disease)
GreatData&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Trt Sev
## 1   1   5
## 2   1  15
## 3   1  35
## 4   1  55
## 5   2  11
## 6   2  30
## 7   2  61
## 8   2  75&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;names(GreatData)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Trt&amp;quot; &amp;quot;Sev&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Renaming columns
names(GreatData) &amp;lt;-c(&amp;#39;Variety&amp;#39;, &amp;#39;Severity&amp;#39;)
GreatData&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Variety Severity
## 1       1        5
## 2       1       15
## 3       1       35
## 4       1       55
## 5       2       11
## 6       2       30
## 7       2       61
## 8       2       75&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;GreatData$Variety&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1 1 1 1 2 2 2 2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;GreatData$Severity&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  5 15 35 55 11 30 61 75&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Integrating Functions&lt;/strong&gt;
In R, as well as in many other programming languages, we can combine functions to simply the number of lines of code.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dap&amp;lt;-c(7,14,21,28,35,42,49)
dis1&amp;lt;-c(0,5,7,25,55,60,75)
dis2&amp;lt;-c(3,14,33,50,65,75,78)

progress&amp;lt;-data.frame(cbind(dap,dis1,dis2)) #We combined data.frame() and cbind()
progress&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   dap dis1 dis2
## 1   7    0    3
## 2  14    5   14
## 3  21    7   33
## 4  28   25   50
## 5  35   55   65
## 6  42   60   75
## 7  49   75   78&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(progress)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;data.frame&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;####&lt;strong&gt;Lists&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Understanding how R interprets and formats your data is critical since at times you will need to identify specific components of an output for further analyses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;L28 &amp;lt;- list(c(1,2,3),1000,seq(1,2,.1))
L28&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## [1] 1 2 3
## 
## [[2]]
## [1] 1000
## 
## [[3]]
##  [1] 1.0 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;L28[[3]] # third component of list&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 1.0 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;L28[[3]][4] # fourth entry in third component of list&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;####&lt;strong&gt;Illustration of a list of information&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;field.work=list(loc=&amp;quot;Janesville&amp;quot;,year=2010,field=&amp;quot;Soybean&amp;quot;,trts=c(&amp;quot;A&amp;quot;,&amp;quot;B&amp;quot;,&amp;quot;C&amp;quot;),assess=c(7,14,21,28,35,42))

field.work&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $loc
## [1] &amp;quot;Janesville&amp;quot;
## 
## $year
## [1] 2010
## 
## $field
## [1] &amp;quot;Soybean&amp;quot;
## 
## $trts
## [1] &amp;quot;A&amp;quot; &amp;quot;B&amp;quot; &amp;quot;C&amp;quot;
## 
## $assess
## [1]  7 14 21 28 35 42&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;names(field.work)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;loc&amp;quot;    &amp;quot;year&amp;quot;   &amp;quot;field&amp;quot;  &amp;quot;trts&amp;quot;   &amp;quot;assess&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;field.work$field&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Soybean&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;####&lt;strong&gt;Logical operators&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;8 &amp;lt; 10 # Try this&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;8 == 10 # The double equal signs are used for logical statements&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;8 != 10 # The exclamation point means ‘not’&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;X &amp;lt;- 1:10
X &amp;lt; 8&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;X &amp;lt; 8 &amp;amp; X &amp;gt; 3 # The ampersand means ‘and’, both must be true&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;X &amp;lt; 3 | X &amp;gt; 8 # The ‘|’ means ‘or’, either must be true&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(X &amp;lt; 8)/10 * 100 &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 70&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;####&lt;strong&gt;Character Data&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;A1 &amp;lt;- c(&amp;#39;Severity&amp;#39;, &amp;#39;Yield&amp;#39;) 
A1[1]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Severity&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;A2 &amp;lt;- paste(&amp;#39;Disease&amp;#39;, &amp;#39;Severity&amp;#39;)
A2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Disease Severity&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;A3 &amp;lt;- paste(&amp;#39;B&amp;#39;, 1:10, sep=&amp;#39;&amp;#39;) # specifies no space between betwen the characters
A3&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;B1&amp;quot;  &amp;quot;B2&amp;quot;  &amp;quot;B3&amp;quot;  &amp;quot;B4&amp;quot;  &amp;quot;B5&amp;quot;  &amp;quot;B6&amp;quot;  &amp;quot;B7&amp;quot;  &amp;quot;B8&amp;quot;  &amp;quot;B9&amp;quot;  &amp;quot;B10&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;A4 &amp;lt;- paste(&amp;#39;B&amp;#39;, 1:10, sep=&amp;#39;-&amp;#39;) # a dash goes between the characters
A4&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;B-1&amp;quot;  &amp;quot;B-2&amp;quot;  &amp;quot;B-3&amp;quot;  &amp;quot;B-4&amp;quot;  &amp;quot;B-5&amp;quot;  &amp;quot;B-6&amp;quot;  &amp;quot;B-7&amp;quot;  &amp;quot;B-8&amp;quot;  &amp;quot;B-9&amp;quot;  &amp;quot;B-10&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;D1 &amp;lt;- &amp;#39;Mississippi&amp;#39;
substring(D1, 1,4) # takes letters 1 through 4&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Miss&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;C1 &amp;lt;- paste(&amp;#39;B&amp;#39;, 1:10, sep=&amp;#39; &amp;#39;) 
C1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;B 1&amp;quot;  &amp;quot;B 2&amp;quot;  &amp;quot;B 3&amp;quot;  &amp;quot;B 4&amp;quot;  &amp;quot;B 5&amp;quot;  &amp;quot;B 6&amp;quot;  &amp;quot;B 7&amp;quot;  &amp;quot;B 8&amp;quot;  &amp;quot;B 9&amp;quot;  &amp;quot;B 10&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;substring(C1,1,1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;B&amp;quot; &amp;quot;B&amp;quot; &amp;quot;B&amp;quot; &amp;quot;B&amp;quot; &amp;quot;B&amp;quot; &amp;quot;B&amp;quot; &amp;quot;B&amp;quot; &amp;quot;B&amp;quot; &amp;quot;B&amp;quot; &amp;quot;B&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;substring(C1,1,2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;B &amp;quot; &amp;quot;B &amp;quot; &amp;quot;B &amp;quot; &amp;quot;B &amp;quot; &amp;quot;B &amp;quot; &amp;quot;B &amp;quot; &amp;quot;B &amp;quot; &amp;quot;B &amp;quot; &amp;quot;B &amp;quot; &amp;quot;B &amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;substring(C1,1,3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;B 1&amp;quot; &amp;quot;B 2&amp;quot; &amp;quot;B 3&amp;quot; &amp;quot;B 4&amp;quot; &amp;quot;B 5&amp;quot; &amp;quot;B 6&amp;quot; &amp;quot;B 7&amp;quot; &amp;quot;B 8&amp;quot; &amp;quot;B 9&amp;quot; &amp;quot;B 1&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;substring(C1,1,4) #Where is the difference with the previous example?&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;B 1&amp;quot;  &amp;quot;B 2&amp;quot;  &amp;quot;B 3&amp;quot;  &amp;quot;B 4&amp;quot;  &amp;quot;B 5&amp;quot;  &amp;quot;B 6&amp;quot;  &amp;quot;B 7&amp;quot;  &amp;quot;B 8&amp;quot;  &amp;quot;B 9&amp;quot;  &amp;quot;B 10&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Indices for Selecting Subsets&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Suppose we have a set of labels for experimental units
D5n &amp;lt;- rep(1:10,3) 
D5c &amp;lt;- c(rep(&amp;#39;A&amp;#39;,10), rep(&amp;#39;B&amp;#39;,10), rep(&amp;#39;C&amp;#39;,10))
D5 &amp;lt;- paste(D5c,D5n,sep=&amp;#39;&amp;#39;)
D5&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;A1&amp;quot;  &amp;quot;A2&amp;quot;  &amp;quot;A3&amp;quot;  &amp;quot;A4&amp;quot;  &amp;quot;A5&amp;quot;  &amp;quot;A6&amp;quot;  &amp;quot;A7&amp;quot;  &amp;quot;A8&amp;quot;  &amp;quot;A9&amp;quot;  &amp;quot;A10&amp;quot; &amp;quot;B1&amp;quot; 
## [12] &amp;quot;B2&amp;quot;  &amp;quot;B3&amp;quot;  &amp;quot;B4&amp;quot;  &amp;quot;B5&amp;quot;  &amp;quot;B6&amp;quot;  &amp;quot;B7&amp;quot;  &amp;quot;B8&amp;quot;  &amp;quot;B9&amp;quot;  &amp;quot;B10&amp;quot; &amp;quot;C1&amp;quot;  &amp;quot;C2&amp;quot; 
## [23] &amp;quot;C3&amp;quot;  &amp;quot;C4&amp;quot;  &amp;quot;C5&amp;quot;  &amp;quot;C6&amp;quot;  &amp;quot;C7&amp;quot;  &amp;quot;C8&amp;quot;  &amp;quot;C9&amp;quot;  &amp;quot;C10&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# We can make an index to select only those in treatment A
Aindex &amp;lt;- substring(D5,1,1) == &amp;#39;A&amp;#39;
# Suppose this is the corresponding list of yields
Yield &amp;lt;- 1:30
# We can apply the logical index to select only those yields corresponding to treatment A
Yield[Aindex]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  1  2  3  4  5  6  7  8  9 10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;####&lt;strong&gt;Loops&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Many times we are interested in repeating some calculations. In R, there are many methods to do this, including the use of loops. We will also see some other methods that improve programming performance when we are interested in repeating a specific function many times.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;K1 &amp;lt;- c(4,2,8,5)
L1 &amp;lt;- c(1,3,4,2)
M1 &amp;lt;- 0*1:4  # This in the object where we will place the answer to our query
M1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0 0 0 0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# This loop finds the maximum of K1 and L1 at each position
for (j in 1:4){
  M1[j] &amp;lt;- max(K1[j],L1[j])
}

M1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 4 3 8 5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;####&lt;strong&gt;Apply a function&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;While loops work well for some functions and programming, they are rather inefficient for large operations. In R, we can take advantage of the functions: apply(), lapply() and tapply().&lt;/p&gt;
&lt;p&gt;Using the help() options, we can see that:&lt;/p&gt;
&lt;p&gt;apply() = returns a vector or array or list of values obtained by applying a function to margins of an array or matrix&lt;/p&gt;
&lt;p&gt;lapply() = returns a list of the same length of X, where each element is the result of applying a function to the corresponding element of X&lt;/p&gt;
&lt;p&gt;tapply() = apply a function to each cell a ragged array, meaning that the function is applied to each, non-empty group of values given by a unique combination of the levels of certain factors&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#apply() - works on rows or columns

group1&amp;lt;-rnorm(10,5,2)
group2&amp;lt;-rnorm(10,10,5)
group3&amp;lt;-rnorm(10,15,7)

example.apply&amp;lt;-cbind(group1,group2,group3)
apply(example.apply, MARGIN=2, mean)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    group1    group2    group3 
##  5.342142  9.459058 16.865356&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;apply(example.apply, MARGIN=2, sd)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   group1   group2   group3 
## 1.805927 4.389215 6.810194&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;apply(example.apply, MARGIN=2, function (x) sd(x)/mean(x))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    group1    group2    group3 
## 0.3380529 0.4640224 0.4037979&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#lapply() - works on a list
L28 &amp;lt;- list(c(1,2,3),1000,seq(1,2,.1))
L28&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## [1] 1 2 3
## 
## [[2]]
## [1] 1000
## 
## [[3]]
##  [1] 1.0 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lapply(L28,mean)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## [1] 2
## 
## [[2]]
## [1] 1000
## 
## [[3]]
## [1] 1.5&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#tapply() - works to summarize information by some defined factor
factor&amp;lt;-rep(c(&amp;quot;A&amp;quot;,&amp;quot;B&amp;quot;,&amp;quot;C&amp;quot;,&amp;quot;D&amp;quot;,&amp;quot;E&amp;quot;), each=2)
tapply(example.apply[,1], factor, mean) #Summarizing the first column, by factor&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        A        B        C        D        E 
## 5.393254 5.547669 6.684877 5.772247 3.312664&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tapply(example.apply[,1], factor, sd) #Summarizing the first column, by factor&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         A         B         C         D         E 
## 0.4238861 1.6318971 0.4830597 3.6599872 0.7599961&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tapply(example.apply[,1], factor, function (x) sd(x)/mean(x)) #CV by factor&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          A          B          C          D          E 
## 0.07859563 0.29415907 0.07226156 0.63406628 0.22942143&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Correlation</title>
      <link>/post/correlations/</link>
      <pubDate>Thu, 01 Aug 2019 21:09:09 -0500</pubDate>
      
      <guid>/post/correlations/</guid>
      <description>


&lt;div id=&#34;background&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt;Correlation analysis is helpful to identify the associations between different variables (measurements). For databases with combinations of qualitative and quantitative data, we use this as a preliminary step to understand the likely relationships, or potential explanatory value of different measurements. We will apply some examples here based on &lt;em&gt;tidyverse&lt;/em&gt; to estimate the correlation coefficients based on different methods. We will also visualize the associations graphically. Two primary packages we need for this example are &lt;em&gt;Hmisc&lt;/em&gt; y de &lt;em&gt;corrplot&lt;/em&gt;. We will also use the package &lt;em&gt;readr&lt;/em&gt; to read data into R.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(Hmisc)
library(corrplot)
library(readr)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;database&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Database&lt;/h2&gt;
&lt;p&gt;There are different options for working with data that is in a local folder. For many, the manual options with a data import are easier, but it is also useful to understand how you can directly read data into R. We will use both at time during the workshop, so do not stress too much for now.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Introduce the data to R - in this situation, we apply the function read_csv the most important item is to know the physical location of the file. In this example, I mainain a copy in Documents folder on my Mac
  
correlations &amp;lt;- read_csv(&amp;quot;Correlations.csv&amp;quot;)
correlations&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 54 x 6
##    Treatment Count1 Count2 Yield Protein   Oil
##        &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1         1   241    241  2569.    35.4  19.6
##  2         1   241    250. 2905.    35.8  19.5
##  3         1   241    250. 3186.    36.2  19.3
##  4         2   396.   482  2887.    36    19  
##  5         2   284    275. 3389.    36.3  19.4
##  6         2   293.   310. 3482.    35.5  19.3
##  7         3   465.   473. 2836.    35.6  19.5
##  8         3   422.   456. 3361.    36.2  19.7
##  9         3   370.   379. 3569.    36.4  19.1
## 10         4   413.   448. 2919.    33.9  20  
## # ... with 44 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;pearson&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Pearson&lt;/h2&gt;
&lt;p&gt;We will begin with the first type of correlation, which is the Pearson correlation. In this situation, we assume that we have quantitative variables. Depending on the database, you may just define the function by calling the name of the database. Nonetheless, we do need to understand our database and “clean” this some, especially to ignore the first column that defines some treatment. We will then use the function &lt;em&gt;rcorr&lt;/em&gt;. This function allows us to perform two types of analyses: (1) Pearson and (2) Spearman (nonparametric method).&lt;/p&gt;
&lt;p&gt;In R, and this is something that will carry throughout different types of models and analyses, there are often different packages and functions that we can use. Each has its advantages and disadvantages, for example, some functions do not provide a test statistic. In other cases the method does not permit the use of some of the graphical methods to visualize the associations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# In this first example, the &amp;quot;select&amp;quot; option is indicating that we will use all columns except the first one, which is for treatment

example_cor &amp;lt;- correlations %&amp;gt;% 
  select(-Treatment) %&amp;gt;%
  as.matrix() %&amp;gt;%
  rcorr(type = &amp;quot;pearson&amp;quot;)

example_cor&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         Count1 Count2 Yield Protein   Oil
## Count1    1.00   0.98  0.27    0.02 -0.10
## Count2    0.98   1.00  0.23    0.00 -0.09
## Yield     0.27   0.23  1.00   -0.13 -0.25
## Protein   0.02   0.00 -0.13    1.00 -0.38
## Oil      -0.10  -0.09 -0.25   -0.38  1.00
## 
## n= 54 
## 
## 
## P
##         Count1 Count2 Yield  Protein Oil   
## Count1         0.0000 0.0527 0.9077  0.4726
## Count2  0.0000        0.1017 0.9952  0.4999
## Yield   0.0527 0.1017        0.3677  0.0646
## Protein 0.9077 0.9952 0.3677         0.0047
## Oil     0.4726 0.4999 0.0646 0.0047&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# We will now apply the function corrplot, which is in the package &amp;quot;corrplot&amp;quot; to look at the associations

example_cor2 &amp;lt;- correlations %&amp;gt;% 
  select(-Treatment) %&amp;gt;%
  as.matrix() %&amp;gt;%
  cor(method = &amp;quot;pearson&amp;quot;)

corrplot(example_cor2, method=&amp;quot;number&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/Correlations_files/figure-html/pearson-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;corrplot(example_cor2, method=&amp;quot;circle&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/Correlations_files/figure-html/pearson-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;spearman&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Spearman&lt;/h2&gt;
&lt;p&gt;This is a non-parametric rank-order correlation analysis.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Following again from our example.

example_corB &amp;lt;- correlations %&amp;gt;% 
  select(-Treatment) %&amp;gt;%
  as.matrix() %&amp;gt;%
  rcorr(type = &amp;quot;spearman&amp;quot;)

example_corB&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         Count1 Count2 Yield Protein   Oil
## Count1    1.00   0.97  0.18    0.06 -0.06
## Count2    0.97   1.00  0.16    0.02 -0.06
## Yield     0.18   0.16  1.00   -0.14 -0.21
## Protein   0.06   0.02 -0.14    1.00 -0.41
## Oil      -0.06  -0.06 -0.21   -0.41  1.00
## 
## n= 54 
## 
## 
## P
##         Count1 Count2 Yield  Protein Oil   
## Count1         0.0000 0.1843 0.6741  0.6511
## Count2  0.0000        0.2367 0.8616  0.6477
## Yield   0.1843 0.2367        0.3269  0.1366
## Protein 0.6741 0.8616 0.3269         0.0023
## Oil     0.6511 0.6477 0.1366 0.0023&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Graphically, following from our initial example.

example_corB2 &amp;lt;- correlations %&amp;gt;% 
  select(-Treatment) %&amp;gt;%
  as.matrix() %&amp;gt;%
  cor(method = &amp;quot;spearman&amp;quot;)

corrplot(example_corB2, method=&amp;quot;number&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/Correlations_files/figure-html/spearman-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;corrplot(example_corB2, method=&amp;quot;circle&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/Correlations_files/figure-html/spearman-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;summary&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;The goal of this introductory example was to provide some of the tools we can apply to calculate different correlation coefficients and graph the results. Remember that with these examples we assume a linear correlation so the intepretation of the results need to consider the biological associations as well (think about this for a correlation coefficient of 0 that has a curvilinear relationship).&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Linar regression</title>
      <link>/post/linear_regression/</link>
      <pubDate>Thu, 01 Aug 2019 21:08:10 -0500</pubDate>
      
      <guid>/post/linear_regression/</guid>
      <description>


&lt;div id=&#34;background&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt;This example is focued on modeling via linear regression. We will illustrate the concepts using an example, with particular focus on the assumptions and the tools that exist in R to explore the model fit.&lt;/p&gt;
&lt;p&gt;Our goal is to related a “dependent variable” with an “independent variable” the explains something about the process.&lt;/p&gt;
&lt;p&gt;Our simple example is that we might relate plant height with an index of crop growth (leaf area index). This would provide a simple base for considering in the future the impact of some pest on growth and development.&lt;/p&gt;
&lt;p&gt;Our basic model form is: &lt;span class=&#34;math display&#34;&gt;\[Y = f(X) + e\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Y = dependent variable,&lt;/li&gt;
&lt;li&gt;f(X) = a mathematical function that describes the relationship of the dependenct variable as a function of the independent variable,&lt;/li&gt;
&lt;li&gt;e = error, the proper form for a model depends on the type of assumptions; in our simple example, we assume that the error is distributed normally with an expected value of 0 and variance equal to sigma.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For this first example, we are creating a more complete analysis where we will explore some of the tools that help with understanding the model assumptions and also how to use the prediction function, which is important for using the model to estimate new values, as well as information about the variability.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(Hmisc)
library(corrplot)
library(readr)
library(HH)
library(car)
library(tinytex)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;In the majority of our examples, we will use a manual data input approach, to minimize some of the confusion that occurs when trying to import data. R and RStudio are very flexible in this regards.&lt;/p&gt;
&lt;p&gt;The data we are using for this first example comes from peanut, where we have two measures:
1. The percentage of clean grain,
2. The concentration of aflatoxin in &lt;em&gt;ppb&lt;/em&gt; (ug per kg).&lt;/p&gt;
&lt;p&gt;We describe the variables as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;clean = % of clean grain&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;aflatoxin = aflatoxin concentration&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;clean &amp;lt;- c(99.97, 99.94, 99.86, 99.98, 99.93, 99.81, 99.98, 99.91, 99.88, 99.97, 99.97, 99.8, 99.96, 99.99, 99.86, 99.96, 99.93, 99.79, 99.96, 99.86, 99.82, 99.97, 99.99, 99.83, 99.89, 99.96, 99.72, 99.96, 99.91, 99.64, 99.98, 99.86, 99.66, 99.98)
aflatoxin &amp;lt;- c(3, 18.8, 46.8, 4.7, 18.9, 46.8, 8.3, 21.7, 58.1, 9.3, 21.9, 62.3, 9.9, 22.8, 70.6, 11, 24.2, 71.1, 12.3, 25.8, 71.3, 12.5, 30.6, 83.2, 12.6, 36.2, 83.6, 15.9, 39.8, 99.5, 16.7, 44.3, 111.2, 18.8)

peanut &amp;lt;- data.frame(clean, aflatoxin)
head(peanut)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   clean aflatoxin
## 1 99.97       3.0
## 2 99.94      18.8
## 3 99.86      46.8
## 4 99.98       4.7
## 5 99.93      18.9
## 6 99.81      46.8&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;exploratory-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory analysis&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(aflatoxin)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 36.60294&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sd(aflatoxin)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 29.3194&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sd(aflatoxin)/mean(aflatoxin)*100&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 80.1012&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(clean)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 99.89647&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sd(clean)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.09351332&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sd(clean)/mean(clean)*100&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.09361024&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor(clean, aflatoxin)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -0.9069581&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rcorr(clean, aflatoxin)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       x     y
## x  1.00 -0.91
## y -0.91  1.00
## 
## n= 34 
## 
## 
## P
##   x  y 
## x     0
## y  0&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-regression&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear regression&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Visualizing the relationship
with(peanut, plot(x=clean, y=aflatoxin, xlim=c(99.5,100), ylim=c(0,120), pch=10)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/linear_regression_files/figure-html/regression-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# We will use lm() = linear model, to run the regression

linreg &amp;lt;- with(peanut, lm(aflatoxin~clean)) #Format, Y &amp;lt;- X
anova(linreg) #ANOVA table to see how the model fit looks&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Response: aflatoxin
##           Df  Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## clean      1 23334.5 23334.5  148.36 1.479e-13 ***
## Residuals 32  5033.2   157.3                      
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(linreg) #Another way to see results of the model, with a few more details. This is important as we extend on the modeling concept to understand more complex relationships. &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = aflatoxin ~ clean)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -25.843  -7.997  -2.771   6.835  27.695 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 28443.18    2332.21   12.20 1.43e-13 ***
## clean        -284.36      23.35  -12.18 1.48e-13 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 12.54 on 32 degrees of freedom
## Multiple R-squared:  0.8226, Adjusted R-squared:  0.817 
## F-statistic: 148.4 on 1 and 32 DF,  p-value: 1.479e-13&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The results indicated that there is a “significant” relationship. In the next step, we are going to learn about some of the tools that we can use to extract more information about the results to look at hypothesis testing on the parameters (intercept, slope, etc.)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;### Example: let&amp;#39;s say that we are interested in comparing the slope to a known value of -220, which means that for every 1% change in the percentage of clean grain, the concentration of aflatoxin will be reduced by 220 ug per kg

# First, we need to see and understand where the coefficients are located, especially the intercept and slope
linreg$coef&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## (Intercept)       clean 
##  28443.1778   -284.3601&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;linreg$coef[1]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## (Intercept) 
##    28443.18&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;linreg$coef[2]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     clean 
## -284.3601&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Furthermore, where are the errors associated with each parameter
coefs &amp;lt;- summary(linreg)
names(coefs)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;call&amp;quot;          &amp;quot;terms&amp;quot;         &amp;quot;residuals&amp;quot;     &amp;quot;coefficients&amp;quot;  &amp;quot;aliased&amp;quot;       &amp;quot;sigma&amp;quot;         &amp;quot;df&amp;quot;            &amp;quot;r.squared&amp;quot;     &amp;quot;adj.r.squared&amp;quot; &amp;quot;fstatistic&amp;quot;    &amp;quot;cov.unscaled&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coefs$coefficients&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##               Estimate Std. Error   t value     Pr(&amp;gt;|t|)
## (Intercept) 28443.1778 2332.20556  12.19583 1.429478e-13
## clean        -284.3601   23.34622 -12.18014 1.479070e-13&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# We can see this directly as follows: 
coefs$coefficients[1,1]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 28443.18&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coefs$coefficients[1,2]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2332.206&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coefs$coefficients[2,1]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -284.3601&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coefs$coefficients[2,2]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 23.34622&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Now, we will define the test parameter value for the slope
B1 &amp;lt;- -220

# To realize the test, we need to define the parameter value and the appropriate error term 
# abs = absolute value

test_b1&amp;lt;-abs((coefs$coefficients[2,1]-B1)/coefs$coefficients[2,2])
test_b1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2.75677&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Test statistic (two-tailed) with 32 degrees of freedom (error term) 
2*pt(q=test_b1, df=32, lower.tail=FALSE) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.009560549&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;model-assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model assumptions&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## What does a simple call to plot provide?
plot(linreg)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/linear_regression_files/figure-html/assumptions-1.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;/post/linear_regression_files/figure-html/assumptions-2.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;/post/linear_regression_files/figure-html/assumptions-3.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;/post/linear_regression_files/figure-html/assumptions-4.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## With Rmarkdown and the reporting tools, we may have interest in controlling the outputted graphics, which can be accomplished as follows:
par(mfrow=c(1,1))
plot(linreg, which=1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/linear_regression_files/figure-html/assumptions-5.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(linreg, which=2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/linear_regression_files/figure-html/assumptions-6.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(linreg, which=3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/linear_regression_files/figure-html/assumptions-7.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(linreg, which=4)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/linear_regression_files/figure-html/assumptions-8.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(linreg, which=5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/linear_regression_files/figure-html/assumptions-9.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(linreg, which=6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/linear_regression_files/figure-html/assumptions-10.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;estimation-and-prediction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Estimation and prediction&lt;/h2&gt;
&lt;p&gt;Now that we have a model, we are normally interested in performing some type of prediction based on the model equation (form). In R, the function &lt;em&gt;predict()&lt;/em&gt; is very important for many of the modeling tools we might like to apply. This versatile function allows us to perform estimation (within the confines of the model and data structure) and prediction (under uncertainty). What this predicts is the point estimate for a value (or estiamtes for multiple values) as well as the respective interval type (confidence or prediction).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# One challenge with predict is the need to defien a data.frame, even if just for a single value, like the following example where the % clean grain is 99.68. 

observation &amp;lt;- data.frame(clean=99.68)

predict(object=linreg, newdata=observation, interval=&amp;quot;confidence&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        fit      lwr      upr
## 1 98.15855 86.97085 109.3462&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;predict(object=linreg, newdata=observation, interval=&amp;quot;predict&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        fit      lwr     upr
## 1 98.15855 70.27011 126.047&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# We can do the same for all values in the regression. 
intervals&amp;lt;-predict(linreg, interval=&amp;quot;confidence&amp;quot;)
intervals&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          fit       lwr       upr
## 1   15.69411 10.088679  21.29954
## 2   24.22491 19.379382  29.07044
## 3   46.97372 42.261813  51.68563
## 4   12.85051  6.936739  18.76427
## 5   27.06851 22.406270  31.73076
## 6   61.19173 55.183124  67.20034
## 7   12.85051  6.936739  18.76427
## 8   32.75572 28.327614  37.18382
## 9   41.28652 36.835944  45.73710
## 10  15.69411 10.088679  21.29954
## 11  15.69411 10.088679  21.29954
## 12  64.03533 57.691794  70.37887
## 13  18.53771 13.215931  23.85949
## 14  10.00690  3.763770  16.25004
## 15  46.97372 42.261813  51.68563
## 16  18.53771 13.215931  23.85949
## 17  27.06851 22.406270  31.73076
## 18  66.87893 60.183421  73.57445
## 19  18.53771 13.215931  23.85949
## 20  46.97372 42.261813  51.68563
## 21  58.34813 52.654402  64.04186
## 22  15.69411 10.088679  21.29954
## 23  10.00690  3.763770  16.25004
## 24  55.50453 50.102122  60.90693
## 25  38.44292 34.051014  42.83482
## 26  18.53771 13.215931  23.85949
## 27  86.78414 77.317367  96.25092
## 28  18.53771 13.215931  23.85949
## 29  32.75572 28.327614  37.18382
## 30 109.53295 96.573565 122.49234
## 31  12.85051  6.936739  18.76427
## 32  46.97372 42.261813  51.68563
## 33 103.84575 91.777175 115.91433
## 34  12.85051  6.936739  18.76427&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;predictions&amp;lt;-predict(linreg, interval=&amp;quot;predict&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in predict.lm(linreg, interval = &amp;quot;predict&amp;quot;): predictions on current data refer to _future_ responses&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;predictions&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          fit        lwr       upr
## 1   15.69411 -10.459699  41.84791
## 2   24.22491  -1.776625  50.22645
## 3   46.97372  20.996756  72.95069
## 4   12.85051 -13.371114  39.07213
## 5   27.06851   1.100509  53.03652
## 6   61.19173  34.948558  87.43490
## 7   12.85051 -13.371114  39.07213
## 8   32.75572   6.828726  58.68271
## 9   41.28652  15.355682  67.21736
## 10  15.69411 -10.459699  41.84791
## 11  15.69411 -10.459699  41.84791
## 12  64.03533  37.713455  90.35721
## 13  18.53771  -7.556774  44.63219
## 14  10.00690 -16.290956  36.30476
## 15  46.97372  20.996756  72.95069
## 16  18.53771  -7.556774  44.63219
## 17  27.06851   1.100509  53.03652
## 18  66.87893  40.470022  93.28784
## 19  18.53771  -7.556774  44.63219
## 20  46.97372  20.996756  72.95069
## 21  58.34813  32.175256  84.52100
## 22  15.69411 -10.459699  41.84791
## 23  10.00690 -16.290956  36.30476
## 24  55.50453  29.393482  81.61557
## 25  38.44292  12.522086  64.36375
## 26  18.53771  -7.556774  44.63219
## 27  86.78414  59.540418 114.02787
## 28  18.53771  -7.556774  44.63219
## 29  32.75572   6.828726  58.68271
## 30 109.53295  80.887772 138.17814
## 31  12.85051 -13.371114  39.07213
## 32  46.97372  20.996756  72.95069
## 33 103.84575  75.592411 132.09909
## 34  12.85051 -13.371114  39.07213&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# If we are interested in just some select values, it is easy to accomplish this going back to the original single value example:
observations &amp;lt;- data.frame(clean=c(99.5, 99.6, 99.7, 99.8))
predict(object=linreg, newdata=observations, interval=&amp;quot;confidence&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         fit       lwr       upr
## 1 149.34338 129.98701 168.69974
## 2 120.90736 106.14377 135.67095
## 3  92.47135  82.15206 102.79063
## 4  64.03533  57.69179  70.37887&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;predict(object=linreg, newdata=observations, interval=&amp;quot;predict&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         fit       lwr       upr
## 1 149.34338 117.29233 181.39442
## 2 120.90736  91.40203 150.41269
## 3  92.47135  64.91979 120.02290
## 4  64.03533  37.71345  90.35721&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;additional-material&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Additional material&lt;/h2&gt;
&lt;p&gt;The package &lt;em&gt;HH&lt;/em&gt; (Statistical analysis and data display, &lt;a href=&#34;https://www.amazon.com/Statistical-Analysis-Data-Display-Intermediate/dp/1493921215&#34; class=&#34;uri&#34;&gt;https://www.amazon.com/Statistical-Analysis-Data-Display-Intermediate/dp/1493921215&lt;/a&gt;) has various (interesting) functions that we can use to examine a regression model. In the next section, we will look at several of those.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Let&amp;#39;s examine the regression graphically
ci.plot(linreg)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/linear_regression_files/figure-html/HH-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Tools to study the assumptions

# Method to look for outliers using a Bonferroni adjustment
outlierTest(linreg) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## No Studentized residuals with Bonferroni p &amp;lt; 0.05
## Largest |rstudent|:
##    rstudent unadjusted p-value Bonferroni p
## 24 2.425727           0.021292      0.72394&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Quantile-quantile plot based on Student residuals
qqPlot(linreg) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/linear_regression_files/figure-html/HH-2.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## [1] 24 25&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Influence plot in which the size of the circle is proportion to Cook&amp;#39;s distance
influencePlot(linreg) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/linear_regression_files/figure-html/HH-3.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##       StudRes        Hat      CookD
## 24  2.4257274 0.04472257 0.11949821
## 25 -2.2158610 0.02955685 0.06663113
## 30 -0.9262390 0.25734844 0.14930872
## 33  0.6594215 0.22318480 0.06358898&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Test of homoscedasticity 
ncvTest(linreg)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Non-constant Variance Score Test 
## Variance formula: ~ fitted.values 
## Chisquare = 0.183475, Df = 1, p = 0.6684&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Method to verify if there is dependency in the model, which means that a transformation may be appropriate to model the relationship
spreadLevelPlot(linreg) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/linear_regression_files/figure-html/HH-4.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## 
## Suggested power transformation:  0.9466765&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Method to verify if there is evidence that the relationship is not linear
crPlots(linreg)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/linear_regression_files/figure-html/HH-5.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;summary&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;In this exercise, the goal was to introduce different concepts in modeling, using a simple linear regression. With this base, we will extend the modeling idea with different examples that illustrate some of the tools that exist in R when we have more complex relationships. Given the time available for this workshop, even if the subsequent examples are more difficult to understand, this first, more developed example hopefully provides you some of the relevant tools to take the next step in your work to define and use different models. .&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;example&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example&lt;/h2&gt;
&lt;p&gt;The below example looks at the relationship between the weight of chickens as a function of the amount of lysine, which is an essential amino acid in the early phases of development.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;weight &amp;lt;-c(14.7, 17.8, 19.6, 18.4, 20.5, 21.1, 17.2, 18.7, 20.2, 16.0, 17.8, 19.4)
lysine &amp;lt;-c(0.09, 0.14, 0.18, 0.15, 0.16, 0.23, 0.11, 0.19, 0.23, 0.13, 0.17, 0.21)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Modeling methods for regression</title>
      <link>/post/regression_modeling/</link>
      <pubDate>Thu, 01 Aug 2019 21:08:09 -0500</pubDate>
      
      <guid>/post/regression_modeling/</guid>
      <description>


&lt;div id=&#34;background&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt;When building a model, there are different methods we can take to construct it, ranging from manual to automated. There are strengths and weaknesses in using the different methods, but they provide a good background for those interested in taking their models to a higher level (machine level, etc.), since in those situations we are often interested to look for interactions that cannot easily be found with basic approaches.&lt;/p&gt;
&lt;p&gt;The general idea in this example is that we are interested in examining the behaviour of the a dependent variable &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; as a function of different (possible) explanatory variables, &lt;span class=&#34;math inline&#34;&gt;\(X_i\)&lt;/span&gt;. The question that we are asking by looking at the different models is, “Is there a best approach to examing the different relationships?”&lt;/p&gt;
&lt;p&gt;We will examine different approaches in this exercise and be prepared that the final model may not be the same (we will see a different example after that provides a “cleaner” model, if you will).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(Hmisc)
library(corrplot)
library(readr)
library(HH)
library(car)
library(scatterplot3d)
library(leaps)
library(olsrr)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;For this exercise, we will examine the relationshiop between the number of aphids in 34 lots as a function of temperature and relative humidity.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lot &amp;lt;- c(1:34)
aphids &amp;lt;- c(61, 77, 87, 93, 98, 100, 104, 118, 102, 74, 63, 43, 27, 19, 14, 23, 30, 25, 67, 40, 6, 21, 18, 23, 42, 56, 60, 59, 82, 89, 77, 102, 108, 97)
temperature &amp;lt;- c(21, 24.8, 28.3, 26, 27.5, 27.1, 26.8, 29, 28.3, 34, 30.5, 28.3, 30.8, 31, 33.6, 31.8, 31.3, 33.5, 33, 34.5, 34.3, 34.3, 33, 26.5, 32, 27.3, 27.8, 25.8, 25, 18.5, 26, 19, 18, 16.3)
humidity &amp;lt;- c(57,48, 41.5, 56, 58, 31, 36.5, 41, 40, 25, 34, 13, 37, 19, 20, 17, 21, 18.5, 24.5, 16, 6, 26, 21, 26, 28, 24.5, 39, 29, 41, 53.5, 51, 48, 70, 79.5)

aphids_data &amp;lt;- data.frame(lot, aphids, temperature, humidity)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;basic-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Basic model&lt;/h2&gt;
&lt;p&gt;Our basic model is additive, meaning we expect there to be an effect of temperature and relative humidity:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[aphids = intercept + temperature + humidity + error\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Our model structure will start by assuming that both temperature and humidity explain “something” about the relationship. For completeness, one could start with each factor separately and examine the explanatory value and then build the subsequent model accordingly. In many situations, what we are most interested in understanding is if there are interactions that explain better the relationships, especially if it is not clear that a linear set of assumptions is appropriate. We will build on those ideas in subsequent steps.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_a &amp;lt;- with(aphids_data, lm(aphids ~ temperature + humidity))
anova(model_a) # both factors are significant&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Response: aphids
##             Df  Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## temperature  1 15194.8 15194.8 28.7765 7.554e-06 ***
## humidity     1  4813.1  4813.1  9.1151  0.005038 ** 
## Residuals   31 16368.9   528.0                      
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(model_a) #R^2 = 0.55&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = aphids ~ temperature + humidity)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -35.393 -14.006  -3.198  10.335  49.265 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)   
## (Intercept)  35.8255    53.5388   0.669  0.50835   
## temperature  -0.6765     1.4360  -0.471  0.64089   
## humidity      1.2811     0.4243   3.019  0.00504 **
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 22.98 on 31 degrees of freedom
## Multiple R-squared:   0.55,  Adjusted R-squared:  0.521 
## F-statistic: 18.95 on 2 and 31 DF,  p-value: 4.212e-06&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(model_a)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/regression_modeling_files/figure-html/baseline-1.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/post/regression_modeling_files/figure-html/baseline-2.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/post/regression_modeling_files/figure-html/baseline-3.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/post/regression_modeling_files/figure-html/baseline-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(model_a, which=4) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/regression_modeling_files/figure-html/baseline-5.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;full-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Full model&lt;/h2&gt;
&lt;p&gt;The second model we will build takes into account what we define to be the full model. In some situations, this may just be all factors and all interactions. Here, given the two potential explanatory factors and the idea that there may not be purely a linear relationship, we will build our full model based on the individual factors, the interaction between those factors, as well as a quadratic form for the model for each factor.&lt;/p&gt;
&lt;p&gt;Model B: &lt;span class=&#34;math inline&#34;&gt;\(aphids = intercept + temperature + humidity + temperature^2 + humidity^2 + temperature:humidity\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We will use an indicator function to define the quadratic model forms (&lt;span class=&#34;math inline&#34;&gt;\(I\)&lt;/span&gt;) in the subsequent model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_b &amp;lt;- with(aphids_data, lm(aphids ~ temperature + humidity + I(temperature^2) + 
                                  I(humidity^2) + temperature:humidity))
anova(model_b) # significant factors: temperature, humidity, I(temperature^2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Response: aphids
##                      Df  Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## temperature           1 15194.8 15194.8 31.4527 5.278e-06 ***
## humidity              1  4813.1  4813.1  9.9629  0.003801 ** 
## I(temperature^2)      1  1982.4  1982.4  4.1036  0.052418 .  
## I(humidity^2)         1   805.1   805.1  1.6666  0.207279    
## temperature:humidity  1    54.6    54.6  0.1129  0.739344    
## Residuals            28 13526.8   483.1                      
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(model_b) #R^2 = 0.63, adjusted R^2 = 0.5617&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = aphids ~ temperature + humidity + I(temperature^2) + 
##     I(humidity^2) + temperature:humidity)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -41.700 -12.220  -1.462  10.894  41.673 
## 
## Coefficients:
##                        Estimate Std. Error t value Pr(&amp;gt;|t|)
## (Intercept)          143.069144 610.542500   0.234    0.816
## temperature           -5.639044  33.900957  -0.166    0.869
## humidity              -0.182206   8.875236  -0.021    0.984
## I(temperature^2)       0.029174   0.476345   0.061    0.952
## I(humidity^2)         -0.008121   0.036214  -0.224    0.824
## temperature:humidity   0.078534   0.233701   0.336    0.739
## 
## Residual standard error: 21.98 on 28 degrees of freedom
## Multiple R-squared:  0.6281, Adjusted R-squared:  0.5617 
## F-statistic:  9.46 on 5 and 28 DF,  p-value: 2.285e-05&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(model_b)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/regression_modeling_files/figure-html/full-1.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/post/regression_modeling_files/figure-html/full-2.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/post/regression_modeling_files/figure-html/full-3.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/post/regression_modeling_files/figure-html/full-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(model_b, which=4)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/regression_modeling_files/figure-html/full-5.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-comparison&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model comparison&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# anova(a,b), enables comparision between nested models, based on the number of additional parameters

anova(model_a, model_b) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Model 1: aphids ~ temperature + humidity
## Model 2: aphids ~ temperature + humidity + I(temperature^2) + I(humidity^2) + 
##     temperature:humidity
##   Res.Df   RSS Df Sum of Sq     F Pr(&amp;gt;F)
## 1     31 16369                          
## 2     28 13527  3    2842.1 1.961 0.1427&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# What the results indicates is that a full model does not explain better the relationship, probably due to being an over-adjusted model. This does not mean that they may not be a model that better explains the relationship that is less complicated. &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;modeling-three-methods-under-consideration&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Modeling: three methods under consideration&lt;/h2&gt;
&lt;p&gt;Now, we will look at different methods to try to automate the model development. The general idea with this approach/exercise is to reduce the need to create many models and duplicate the same process over and over. The challenge will be to identify the most important factors, not just statistically, but also based on the biology and knowledge of the system.&lt;/p&gt;
&lt;p&gt;The three methods we will consider:
* Manual
* Stepwise methods (“steps”)
* Best subset methods&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Manual model construction
# We will start with Model B in this situation and try to reduce the complexity of the model. 

# The process involves elminating factors that are not significant followed by an examination of the new model fit.

# We assume that we will work from interactions towards the simple, single factor models.

# Initial step: eliminate the factor, temperature:humidity
model_b2 &amp;lt;- update(model_b, .~.-temperature:humidity)
summary(model_b2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = aphids ~ temperature + humidity + I(temperature^2) + 
##     I(humidity^2))
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -40.969 -12.837  -1.096  12.670  41.617 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&amp;gt;|t|)  
## (Intercept)      -57.45005  127.24411  -0.451   0.6550  
## temperature        5.24487    9.85861   0.532   0.5988  
## humidity           2.77322    1.17389   2.362   0.0251 *
## I(temperature^2)  -0.11851    0.18088  -0.655   0.5175  
## I(humidity^2)     -0.01921    0.01465  -1.311   0.2001  
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 21.64 on 29 degrees of freedom
## Multiple R-squared:  0.6266, Adjusted R-squared:  0.5752 
## F-statistic: 12.17 on 4 and 29 DF,  p-value: 6.302e-06&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anova(model_b, model_b2) ## temperature:humidity = non-significant&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Model 1: aphids ~ temperature + humidity + I(temperature^2) + I(humidity^2) + 
##     temperature:humidity
## Model 2: aphids ~ temperature + humidity + I(temperature^2) + I(humidity^2)
##   Res.Df   RSS Df Sum of Sq      F Pr(&amp;gt;F)
## 1     28 13527                           
## 2     29 13581 -1   -54.554 0.1129 0.7393&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# From model b2, we will now eliminate the factor I(humidity^2)
model_b3 &amp;lt;- update(model_b2, .~.-I(humidity^2))
summary(model_b3) # it appears that all factors explain something&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = aphids ~ temperature + humidity + I(temperature^2))
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -37.782 -13.595  -3.561   9.367  43.291 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&amp;gt;|t|)   
## (Intercept)      -152.5753   105.7801  -1.442  0.15955   
## temperature        13.9936     7.3439   1.905  0.06634 . 
## humidity            1.3263     0.4050   3.275  0.00267 **
## I(temperature^2)   -0.2769     0.1362  -2.033  0.05096 . 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 21.9 on 30 degrees of freedom
## Multiple R-squared:  0.6045, Adjusted R-squared:  0.565 
## F-statistic: 15.29 on 3 and 30 DF,  p-value: 3.217e-06&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Compare the models b2 and b3
anova(model_b2, model_b3) # I(humidity^2) = not signficant &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Model 1: aphids ~ temperature + humidity + I(temperature^2) + I(humidity^2)
## Model 2: aphids ~ temperature + humidity + I(temperature^2)
##   Res.Df   RSS Df Sum of Sq      F Pr(&amp;gt;F)
## 1     29 13581                           
## 2     30 14386 -1   -805.11 1.7191 0.2001&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Compare with baseline model
anova(model_a, model_b3) ## this model is close to p=0,05 and probably has &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Model 1: aphids ~ temperature + humidity
## Model 2: aphids ~ temperature + humidity + I(temperature^2)
##   Res.Df   RSS Df Sum of Sq      F  Pr(&amp;gt;F)  
## 1     31 16369                              
## 2     30 14386  1    1982.4 4.1339 0.05096 .
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# some predictive value

# From model b2 (no interaction), we will now remove temperature to 
# look at the humidity^2 term
model_b3t &amp;lt;- update(model_b2, .~.-I(temperature^2))
summary(model_b3t) # it appears that all factors explain something&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = aphids ~ temperature + humidity + I(humidity^2))
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -41.466 -10.864  -0.372   9.754  42.475 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&amp;gt;|t|)   
## (Intercept)   18.95111   50.44302   0.376  0.70979   
## temperature   -1.15206    1.35435  -0.851  0.40171   
## humidity       3.24552    0.91764   3.537  0.00134 **
## I(humidity^2) -0.02563    0.01080  -2.373  0.02426 * 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 21.43 on 30 degrees of freedom
## Multiple R-squared:  0.6211, Adjusted R-squared:  0.5832 
## F-statistic: 16.39 on 3 and 30 DF,  p-value: 1.711e-06&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anova(model_a, model_b3t)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Model 1: aphids ~ temperature + humidity
## Model 2: aphids ~ temperature + humidity + I(humidity^2)
##   Res.Df   RSS Df Sum of Sq    F  Pr(&amp;gt;F)  
## 1     31 16369                            
## 2     30 13782  1    2586.5 5.63 0.02426 *
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anova(model_b2, model_b3t)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Model 1: aphids ~ temperature + humidity + I(temperature^2) + I(humidity^2)
## Model 2: aphids ~ temperature + humidity + I(humidity^2)
##   Res.Df   RSS Df Sum of Sq      F Pr(&amp;gt;F)
## 1     29 13581                           
## 2     30 13782 -1   -201.05 0.4293 0.5175&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# From model b3, remove temperature^2 (can do the same with model_b3t)
model_b4 &amp;lt;- update(model_b3, .~.-I(temperature^2))
anova(model_b4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Response: aphids
##             Df  Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## temperature  1 15194.8 15194.8 28.7765 7.554e-06 ***
## humidity     1  4813.1  4813.1  9.1151  0.005038 ** 
## Residuals   31 16368.9   528.0                      
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(model_b4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = aphids ~ temperature + humidity)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -35.393 -14.006  -3.198  10.335  49.265 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)   
## (Intercept)  35.8255    53.5388   0.669  0.50835   
## temperature  -0.6765     1.4360  -0.471  0.64089   
## humidity      1.2811     0.4243   3.019  0.00504 **
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 22.98 on 31 degrees of freedom
## Multiple R-squared:   0.55,  Adjusted R-squared:  0.521 
## F-statistic: 18.95 on 2 and 31 DF,  p-value: 4.212e-06&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anova(model_b3, model_b4) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Model 1: aphids ~ temperature + humidity + I(temperature^2)
## Model 2: aphids ~ temperature + humidity
##   Res.Df   RSS Df Sum of Sq      F  Pr(&amp;gt;F)  
## 1     30 14386                              
## 2     31 16369 -1   -1982.4 4.1339 0.05096 .
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# You can continue reducing the model, but we do know now that there is some predictive value with the variables we have &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;stepwise-methods&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Stepwise methods&lt;/h2&gt;
&lt;p&gt;Now, let’s use the function &lt;em&gt;step()&lt;/em&gt; to automate the search process for the best model.&lt;/p&gt;
&lt;p&gt;What is required typically is the definition of the null model and the full model. With these defined, we can use “forward”, “backward”, or “both” direction searching.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Stepwise methods

# Null model
model_null &amp;lt;- lm(aphids~1, data=aphids_data)
model_full &amp;lt;- model_b

# Forward
forward &amp;lt;- step(model_null, scope=list(lower=model_null, upper=model_full, 
                                       direction=&amp;quot;forward&amp;quot;)) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Start:  AIC=239.16
## aphids ~ 1
## 
##                    Df Sum of Sq   RSS    AIC
## + humidity          1     19891 16486 214.25
## + I(temperature^2)  1     16098 20279 221.29
## + I(humidity^2)     1     15560 20817 222.18
## + temperature       1     15195 21182 222.77
## &amp;lt;none&amp;gt;                          36377 239.16
## 
## Step:  AIC=214.25
## aphids ~ humidity
## 
##                    Df Sum of Sq   RSS    AIC
## + I(humidity^2)     1    2371.2 14115 210.97
## &amp;lt;none&amp;gt;                          16486 214.25
## + I(temperature^2)  1     358.4 16128 215.51
## + temperature       1     117.2 16369 216.01
## - humidity          1   19890.7 36377 239.16
## 
## Step:  AIC=210.97
## aphids ~ humidity + I(humidity^2)
## 
##                    Df Sum of Sq   RSS    AIC
## &amp;lt;none&amp;gt;                          14115 210.97
## + I(temperature^2)  1     400.9 13714 211.99
## + temperature       1     332.4 13782 212.16
## - I(humidity^2)     1    2371.2 16486 214.25
## - humidity          1    6702.0 20817 222.18&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Backwards
back &amp;lt;- step(model_null, scope=list(lower=model_null, upper=model_full, 
                                    direction=&amp;quot;backward&amp;quot;))  &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Start:  AIC=239.16
## aphids ~ 1
## 
##                    Df Sum of Sq   RSS    AIC
## + humidity          1     19891 16486 214.25
## + I(temperature^2)  1     16098 20279 221.29
## + I(humidity^2)     1     15560 20817 222.18
## + temperature       1     15195 21182 222.77
## &amp;lt;none&amp;gt;                          36377 239.16
## 
## Step:  AIC=214.25
## aphids ~ humidity
## 
##                    Df Sum of Sq   RSS    AIC
## + I(humidity^2)     1    2371.2 14115 210.97
## &amp;lt;none&amp;gt;                          16486 214.25
## + I(temperature^2)  1     358.4 16128 215.51
## + temperature       1     117.2 16369 216.01
## - humidity          1   19890.7 36377 239.16
## 
## Step:  AIC=210.97
## aphids ~ humidity + I(humidity^2)
## 
##                    Df Sum of Sq   RSS    AIC
## &amp;lt;none&amp;gt;                          14115 210.97
## + I(temperature^2)  1     400.9 13714 211.99
## + temperature       1     332.4 13782 212.16
## - I(humidity^2)     1    2371.2 16486 214.25
## - humidity          1    6702.0 20817 222.18&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Both directions 
back &amp;lt;- step(model_null, scope=list(lower=model_null, upper=model_full, 
                                    direction=&amp;quot;both&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Start:  AIC=239.16
## aphids ~ 1
## 
##                    Df Sum of Sq   RSS    AIC
## + humidity          1     19891 16486 214.25
## + I(temperature^2)  1     16098 20279 221.29
## + I(humidity^2)     1     15560 20817 222.18
## + temperature       1     15195 21182 222.77
## &amp;lt;none&amp;gt;                          36377 239.16
## 
## Step:  AIC=214.25
## aphids ~ humidity
## 
##                    Df Sum of Sq   RSS    AIC
## + I(humidity^2)     1    2371.2 14115 210.97
## &amp;lt;none&amp;gt;                          16486 214.25
## + I(temperature^2)  1     358.4 16128 215.51
## + temperature       1     117.2 16369 216.01
## - humidity          1   19890.7 36377 239.16
## 
## Step:  AIC=210.97
## aphids ~ humidity + I(humidity^2)
## 
##                    Df Sum of Sq   RSS    AIC
## &amp;lt;none&amp;gt;                          14115 210.97
## + I(temperature^2)  1     400.9 13714 211.99
## + temperature       1     332.4 13782 212.16
## - I(humidity^2)     1    2371.2 16486 214.25
## - humidity          1    6702.0 20817 222.18&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;return-to-manual-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Return to manual model&lt;/h2&gt;
&lt;p&gt;For the moment, let’s return to our manual model to take a look at suggest model from the stepwise procedure.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_b5&amp;lt;-with(aphids_data, lm(aphids~humidity+I(humidity^2)))
anova(model_b5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Response: aphids
##               Df  Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## humidity       1 19890.7 19890.7 43.6854 2.194e-07 ***
## I(humidity^2)  1  2371.2  2371.2  5.2079    0.0295 *  
## Residuals     31 14114.8   455.3                      
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(model_b5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = aphids ~ humidity + I(humidity^2))
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -44.703 -13.018  -0.288  12.098  40.196 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)   -21.54288   16.60909  -1.297 0.204184    
## humidity        3.41812    0.89093   3.837 0.000574 ***
## I(humidity^2)  -0.02427    0.01063  -2.282 0.029504 *  
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 21.34 on 31 degrees of freedom
## Multiple R-squared:  0.612,  Adjusted R-squared:  0.5869 
## F-statistic: 24.45 on 2 and 31 DF,  p-value: 4.238e-07&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;best-subsets&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Best subsets&lt;/h2&gt;
&lt;p&gt;In the last section of this exercise, we will use a method based on best subsets regression. We will use the funtion &lt;em&gt;regsubsets&lt;/em&gt; in the package &lt;em&gt;leaps&lt;/em&gt; to do this exercise. This method looks at the full model and considers different combinations of models based on the number of best models we decide to examine. The result is not necessarily what is the best model but rather a series of models that explain something in our model. We would then need to go back, after model selection, and run the formal analysis to look at model fit, predictive value, biological relevance, etc..&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# regsubsets = package *leaps*

# let&amp;#39;s start by looking at the best 3 models per level
subsets &amp;lt;- regsubsets(aphids~temperature+humidity+I(temperature^2)+
I(humidity^2)+temperature:humidity, nbest=3, data=aphids_data)

plot(subsets, scale=&amp;quot;adjr2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/regression_modeling_files/figure-html/bestsubsets-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(subsets, scale=&amp;quot;bic&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/regression_modeling_files/figure-html/bestsubsets-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(subsets, scale=&amp;quot;Cp&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/regression_modeling_files/figure-html/bestsubsets-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;summary&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;Hopefully you saw that this was not an easy exercise since there was not a clear model that best fit the response. In modeling we are integrating mathematical/statistical concepts with computational methodology, as well as keeping in mind the biology/pathology.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;What is the best method to model observaed relationships?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;For this concluding part, I draw and adapt on ideas from Gelman and Hall (2007; &lt;em&gt;Data Analysis Using Regression and Multilevel/Hierarchical Models&lt;/em&gt;):&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Include all variables that for reasons known to the researcher may be important for predicting an outcome.&lt;/li&gt;
&lt;li&gt;You do not always have to include all inputs as separate predictors. You can consider in some situations that several inputs could be averaged or summed to create a “total score” that then becomes the predictor variable (index value, etc.)&lt;/li&gt;
&lt;li&gt;For predictive variables with large effects, an examination of the interactions may also be warranted (very common when we extend this to regression trees and other methods).&lt;/li&gt;
&lt;li&gt;Strategy for decisions focused on excluding a variable based on the expected sign and statistical significance:&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;If the predictor is not statistically significant and has the expected sign (+ or -), in general it is fine to keep the predictor. This means that while the predictor is not helping predictions dramatically, it is also not hurting them.&lt;/li&gt;
&lt;li&gt;If the predictor is not statistically significant and does not have the expected sign, consider removing this from the model (i.e., the coefficiente is set to 0).&lt;/li&gt;
&lt;li&gt;If the predictor is statistically significant but does not have the expected sign, this is somewhat more complicated since the challenge is in terms of interpretation. Consider trying to gather additional data on lurking variables and include those in the analysis.&lt;/li&gt;
&lt;li&gt;If the predictor is statistically significant and has the expected sign, definitely you should keep this in the model!&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Multiple regression</title>
      <link>/post/multiple_regression/</link>
      <pubDate>Thu, 01 Aug 2019 21:08:08 -0500</pubDate>
      
      <guid>/post/multiple_regression/</guid>
      <description>


&lt;div id=&#34;background&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt;Given the background and tools presented in linear regression, we will not extend the modeling approach to include additional variables, as well as relationships that are more complicated. This exercise provides the jumping off point for more automated modeling approaches, which will we see in the subsequent example(s).&lt;/p&gt;
&lt;p&gt;Our assumption in this exercise is that multiple factors have explanatory value to explain the response variable of interest.&lt;/p&gt;
&lt;p&gt;What does a model of this type look like? Some examples include:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Additive.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(Y = \beta_0 + \beta_1{X_1} + \beta_2{X_2} + \epsilon\)&lt;/span&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;With interaction between the two terms.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(Y = \beta_0 + \beta_1{X_1} + \beta_2{X_2} + \beta_3{X_1}{X_2} + \epsilon\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Note: It is important to note that in modeling, when we add new explanatory variables that have merit (i.e., the sign makes sense in terms of the biological relation), the model will improve. This is not necessarily the same as being “biologically relevant”. We should always consider the variable in the context of the question of interest.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(Hmisc)
library(corrplot)
library(readr)
library(HH)
library(car)
library(scatterplot3d)
library(olsrr)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;data-and-exploratory-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data and exploratory analysis&lt;/h2&gt;
&lt;p&gt;Our database comes from counts of the number of aphids in different lots, as well as measures of average temperature and relative humidity. We assume that there is a relationship between those two latter factors with the observed number of aphids, which means from a predictive value, we hope that by just measuring T and RH, we can estimate the number of expected aphids.&lt;/p&gt;
&lt;p&gt;Where do we start? The main question is to determine if there is (are) a relationship between T and RH with the counts. We are also interested in trying to determine if there may be a complext relationship (i.e., that the predictive values have some degree of interpretable interaction).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lot &amp;lt;- c(1:34)
aphids &amp;lt;- c(61, 77, 87, 93, 98, 100, 104, 118, 102, 74, 63, 43, 27, 19, 14, 23, 30, 25, 67, 40, 6, 21, 18, 23, 42, 56, 60, 59, 82, 89, 77, 102, 108, 97)
temperature &amp;lt;- c(21, 24.8, 28.3, 26, 27.5, 27.1, 26.8, 29, 28.3, 34, 30.5, 28.3, 30.8, 31, 33.6, 31.8, 31.3, 33.5, 33, 34.5, 34.3, 34.3, 33, 26.5, 32, 27.3, 27.8, 25.8, 25, 18.5, 26, 19, 18, 16.3)
humidity &amp;lt;- c(57,48, 41.5, 56, 58, 31, 36.5, 41, 40, 25, 34, 13, 37, 19, 20, 17, 21, 18.5, 24.5, 16, 6, 26, 21, 26, 28, 24.5, 39, 29, 41, 53.5, 51, 48, 70, 79.5)

aphids_data &amp;lt;- data.frame(lot, aphids, temperature, humidity)

# Quick exploratory analysis
summary(aphids_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       lot            aphids        temperature       humidity    
##  Min.   : 1.00   Min.   :  6.00   Min.   :16.30   Min.   : 6.00  
##  1st Qu.: 9.25   1st Qu.: 27.75   1st Qu.:26.00   1st Qu.:21.88  
##  Median :17.50   Median : 62.00   Median :28.30   Median :32.50  
##  Mean   :17.50   Mean   : 61.91   Mean   :28.09   Mean   :35.19  
##  3rd Qu.:25.75   3rd Qu.: 92.00   3rd Qu.:31.95   3rd Qu.:46.38  
##  Max.   :34.00   Max.   :118.00   Max.   :34.50   Max.   :79.50&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor(aphids_data[,2:4])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                 aphids temperature   humidity
## aphids       1.0000000  -0.6463022  0.7394570
## temperature -0.6463022   1.0000000 -0.8313696
## humidity     0.7394570  -0.8313696  1.0000000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(aphids_data[,2:4]) # Graphical matrix
pairs(aphids_data[,2:4]) # Gives us the same thing&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/multiple_regression_files/figure-html/data-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-regression&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear regression&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Factor = temperature (X)

model1&amp;lt;-with(aphids_data, lm(aphids~temperature))
anova(model1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Response: aphids
##             Df Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## temperature  1  15195 15194.8  22.955 3.643e-05 ***
## Residuals   32  21182   661.9                      
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(model1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = aphids ~ temperature)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -45.698 -18.111  -3.143  19.477  60.004 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 182.1386    25.4785   7.149 4.10e-08 ***
## temperature  -4.2808     0.8935  -4.791 3.64e-05 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 25.73 on 32 degrees of freedom
## Multiple R-squared:  0.4177, Adjusted R-squared:  0.3995 
## F-statistic: 22.96 on 1 and 32 DF,  p-value: 3.643e-05&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(model1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/multiple_regression_files/figure-html/linear-1.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;/post/multiple_regression_files/figure-html/linear-2.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;/post/multiple_regression_files/figure-html/linear-3.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;/post/multiple_regression_files/figure-html/linear-4.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Assumptions = values, model1

rstudent(model1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           1           2           3           4           5           6           7           8           9          10          11          12          13          14          15          16          17          18          19          20          21          22          23          24          25          26          27          28          29          30          31          32          33          34 
## -1.28585895  0.04005818  1.02696012  0.87344711  1.34166917  1.35439948  1.47093718  2.56708773  1.66182645  1.54106791  0.44669460 -0.70426322 -0.92092001 -1.21610745 -0.97682293 -0.91330799 -0.71519631 -0.54584549  1.04821427  0.22134400 -1.19286546 -0.57242992 -0.91388994 -1.87539948 -0.12367881 -0.36099265 -0.12169500 -0.49651581  0.26909704 -0.57840180  0.24013268  0.04903167  0.12114783 -0.66038629&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dfbetas(model1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     (Intercept)  temperature
## 1  -0.366682839  0.331661207
## 2   0.005815635 -0.004670407
## 3   0.023305013  0.007772618
## 4   0.089808162 -0.064378045
## 5   0.067723562 -0.027686588
## 6   0.087212625 -0.047068694
## 7   0.110092705 -0.066711426
## 8  -0.004133934  0.082814320
## 9   0.037712163  0.012577648
## 10 -0.276055170  0.328520764
## 11 -0.024068323  0.038160258
## 12 -0.015981987 -0.005330265
## 13  0.059303647 -0.088531881
## 14  0.086856812 -0.125611236
## 15  0.160634492 -0.193579923
## 16  0.091034920 -0.120629792
## 17  0.058637009 -0.081569976
## 18  0.087768241 -0.106135446
## 19 -0.149512336  0.184383492
## 20 -0.043753984  0.051380499
## 21  0.226920851 -0.267823576
## 22  0.108894329 -0.128522648
## 23  0.130352947 -0.160755509
## 24 -0.160003296  0.104963953
## 25  0.013206774 -0.017231640
## 26 -0.020732461  0.009996651
## 27 -0.004874275  0.001223897
## 28 -0.054538615  0.040127888
## 29  0.037156513 -0.029440595
## 30 -0.223031160  0.207642177
## 31  0.024690533 -0.017699151
## 32  0.017885539 -0.016575675
## 33  0.049290028 -0.046078814
## 34 -0.318930693  0.301601424&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dffits(model1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            1            2            3            4            5            6            7            8            9           10           11           12           13           14           15           16           17           18           19           20           21           22           23           24           25           26           27           28           29           30           31           32           33           34 
## -0.404272806  0.008432063  0.178944815  0.165495030  0.235239322  0.240562702  0.264859612  0.454709984  0.289568427  0.427975171  0.086872782 -0.122715819 -0.183780341 -0.247127470 -0.259852603 -0.200671906 -0.149517430 -0.143648162  0.261386769  0.064842854 -0.342084958 -0.164159053 -0.227891133 -0.343410519 -0.027739070 -0.063654708 -0.021220776 -0.095548871  0.055563960 -0.233580039  0.045498765  0.018866121  0.051306429 -0.327009697&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;covratio(model1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         1         2         3         4         5         6         7         8         9        10        11        12        13        14        15        16        17        18        19        20        21        22        23        24        25        26        27        28        29        30        31        32        33        34 
## 1.0553084 1.1126545 1.0268519 1.0514226 0.9810703 0.9797855 0.9612415 0.7474350 0.9256398 0.9902076 1.0917586 1.0636026 1.0497679 1.0108127 1.0738384 1.0592292 1.0763152 1.1177641 1.0556567 1.1533544 1.0541908 1.1291908 1.0732083 0.8882885 1.1180537 1.0895089 1.0969090 1.0876492 1.1058148 1.2130097 1.0997154 1.2231239 1.2554800 1.2902753&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cooks.distance(model1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            1            2            3            4            5            6            7            8            9           10           11           12           13           14           15           16           17           18           19           20           21           22           23           24           25           26           27           28           29           30           31           32           33           34 
## 8.008297e-02 3.669472e-05 1.598333e-02 1.379652e-02 2.699386e-02 2.819990e-02 3.384457e-02 8.800702e-02 3.973731e-02 8.780865e-02 3.870253e-03 7.650078e-03 1.696816e-02 3.008573e-02 3.381010e-02 2.023952e-02 1.135101e-02 1.054883e-02 3.405642e-02 2.166690e-03 5.774783e-02 1.376327e-02 2.610161e-02 5.466541e-02 3.969427e-04 2.082560e-03 2.323129e-04 4.674868e-03 1.589759e-03 2.785916e-02 1.066474e-03 1.836918e-04 1.357989e-03 5.442676e-02&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Factor = humedad (X)

model2&amp;lt;-with(aphids_data, lm(aphids~humidity))
anova(model2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Response: aphids
##           Df Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## humidity   1  19891 19890.7  38.608 5.857e-07 ***
## Residuals 32  16486   515.2                      
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(model2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = aphids ~ humidity)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -37.53 -13.44  -1.43  12.82  47.68 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  10.9787     9.0744   1.210    0.235    
## humidity      1.4473     0.2329   6.214 5.86e-07 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 22.7 on 32 degrees of freedom
## Multiple R-squared:  0.5468, Adjusted R-squared:  0.5326 
## F-statistic: 38.61 on 1 and 32 DF,  p-value: 5.857e-07&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(model2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/multiple_regression_files/figure-html/linear-5.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;/post/multiple_regression_files/figure-html/linear-6.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;/post/multiple_regression_files/figure-html/linear-7.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;/post/multiple_regression_files/figure-html/linear-8.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Assumptions = values, model2

rstudent(model2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           1           2           3           4           5           6           7           8           9          10          11          12          13          14          15          16          17          18          19          20          21          22          23          24          25          26          27          28          29          30          31          32          33          34 
## -1.52166116 -0.15329366  0.70958337  0.04378704  0.13944816  2.07616739  1.86604477  2.27067980  1.51293060  1.21600986  0.12382267  0.60092052 -1.73010695 -0.88059890 -1.18139920 -0.56699356 -0.50823171 -0.57307681  0.92313524  0.26372262 -0.63535605 -1.25128763 -1.05882161 -1.15657354 -0.42068829  0.42473282 -0.32760978  0.26710592  0.51730586  0.02642984 -0.34840648  0.97153856 -0.20281479 -1.49172395&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dfbetas(model2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     (Intercept)     humidity
## 1   0.203962802 -0.354960067
## 2   0.007091915 -0.020637509
## 3   0.010888321  0.046732070
## 4  -0.005432893  0.009722237
## 5  -0.020090271  0.034108001
## 6   0.237139151 -0.090726882
## 7   0.116375070  0.025442918
## 8   0.045533868  0.137646115
## 9   0.044574968  0.075879906
## 10  0.208590411 -0.129821254
## 11  0.010635007 -0.001536502
## 12  0.175091541 -0.142772652
## 13 -0.099765368 -0.032603908
## 14 -0.202822717  0.150676741
## 15 -0.260370374  0.189329385
## 16 -0.141963444  0.109421496
## 17 -0.106991971  0.075962840
## 18 -0.134852336  0.101178572
## 19  0.162812727 -0.103448492
## 20  0.068702630 -0.053805692
## 21 -0.232992130  0.202795860
## 22 -0.202585666  0.120351428
## 23 -0.222901106  0.158256745
## 24 -0.187251287  0.111241631
## 25 -0.060049112  0.031601350
## 26  0.074909835 -0.047596460
## 27 -0.012732795 -0.013008080
## 28  0.035580371 -0.017261761
## 29  0.010373518  0.031358513
## 30 -0.002627836  0.005134802
## 31  0.026166587 -0.058167303
## 32 -0.044946864  0.130795599
## 33  0.055027998 -0.078907786
## 34  0.575503750 -0.776106220&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dffits(model2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            1            2            3            4            5            6            7            8            9           10           11           12           13           14           15           16           17           18           19           20           21           22           23           24           25           26           27           28           29           30           31           32           33           34 
## -0.447191192 -0.033924951  0.132317421  0.012469416  0.042283274  0.372962648  0.325861688  0.419240517  0.274398674  0.249344653  0.021611110  0.178729735 -0.302985776 -0.216541182 -0.281470975 -0.148585846 -0.117356163 -0.143175941  0.191962176  0.071346658 -0.233677243 -0.249738808 -0.244493286 -0.230835253 -0.079949336  0.088321443 -0.058538076  0.049688881  0.095511299  0.006952189 -0.084642540  0.215008230 -0.087530558 -0.829472811&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;covratio(model2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         1         2         3         4         5         6         7         8         9        10        11        12        13        14        15        16        17        18        19        20        21        22        23        24        25        26        27        28        29        30        31        32        33        34 
## 1.0022713 1.1160516 1.0676446 1.1518269 1.1620673 0.8477864 0.8874781 0.8100232 0.9544553 1.0115565 1.0969300 1.1332631 0.9133416 1.0755087 1.0311057 1.1154780 1.1038994 1.1084567 1.0529470 1.1384310 1.1787935 1.0040208 1.0453923 1.0182323 1.0915424 1.0988072 1.0920026 1.0973744 1.0831002 1.1392331 1.1196610 1.0526653 1.2606798 1.2144142&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cooks.distance(model2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            1            2            3            4            5            6            7            8            9           10           11           12           13           14           15           16           17           18           19           20           21           22           23           24           25           26           27           28           29           30           31           32           33           34 
## 9.604190e-02 5.935641e-04 8.891911e-03 8.024605e-05 9.221958e-04 6.302998e-02 4.927114e-02 7.777970e-02 3.618960e-02 3.062822e-02 2.409338e-04 1.629755e-02 4.320873e-02 2.361072e-02 3.912909e-02 1.127801e-02 7.049632e-03 1.046940e-02 1.851025e-02 2.621394e-03 2.782097e-02 3.064301e-02 2.977580e-02 2.636426e-02 3.280316e-03 4.002862e-03 1.762520e-03 1.271389e-03 4.668043e-03 2.494547e-05 3.683311e-03 2.315487e-02 3.949133e-03 3.313265e-01&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;additive-multiple-regression&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Additive multiple regression&lt;/h2&gt;
&lt;p&gt;Model form:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[aphids = intercept + temperature + humidity + error\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model3&amp;lt;-with(aphids_data, lm(aphids~temperature+humidity))
anova(model3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Response: aphids
##             Df  Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## temperature  1 15194.8 15194.8 28.7765 7.554e-06 ***
## humidity     1  4813.1  4813.1  9.1151  0.005038 ** 
## Residuals   31 16368.9   528.0                      
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(model3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = aphids ~ temperature + humidity)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -35.393 -14.006  -3.198  10.335  49.265 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)   
## (Intercept)  35.8255    53.5388   0.669  0.50835   
## temperature  -0.6765     1.4360  -0.471  0.64089   
## humidity      1.2811     0.4243   3.019  0.00504 **
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 22.98 on 31 degrees of freedom
## Multiple R-squared:   0.55,  Adjusted R-squared:  0.521 
## F-statistic: 18.95 on 2 and 31 DF,  p-value: 4.212e-06&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(model3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/multiple_regression_files/figure-html/TRH-1.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;/post/multiple_regression_files/figure-html/TRH-2.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;/post/multiple_regression_files/figure-html/TRH-3.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;/post/multiple_regression_files/figure-html/TRH-4.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;vif(lm(aphids~temperature+humidity, data=aphids_data))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## temperature    humidity 
##    3.238084    3.238084&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Assumptions = values, model3
rstudent(model3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          1          2          3          4          5          6          7          8          9         10         11         12         13         14         15         16         17         18         19         20         21         22         23         24         25         26         27         28         29         30         31         32         33         34 
## -1.5718383 -0.1554587  0.7588243  0.1370895  0.3068861  1.9975726  1.8135772  2.3619288  1.5465227  1.3436594  0.1864002  0.4608253 -1.6388797 -0.9045838 -1.1176402 -0.5834426 -0.5100256 -0.5278939  0.9931907  0.3134810 -0.6587793 -1.1492651 -1.0051359 -1.3057363 -0.3548909  0.3255590 -0.3044695  0.1559741  0.4639182 -0.1337120 -0.2920664  0.8408516 -0.2500954 -1.5096341&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dfbetas(model3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      (Intercept)  temperature     humidity
## 1  -0.1389605773  0.177983609 -0.057094981
## 2  -0.0001234515  0.001378033 -0.010485457
## 3  -0.0823800284  0.085661206  0.099164620
## 4  -0.0300681549  0.027499212  0.040114310
## 5  -0.1128940158  0.106442807  0.132644719
## 6   0.2933256395 -0.257672477 -0.263133078
## 7   0.1288811603 -0.111084942 -0.078585304
## 8  -0.3419564458  0.355447009  0.375970378
## 9  -0.1277781057  0.137669370  0.157728821
## 10 -0.2545839017  0.299547009  0.167359803
## 11 -0.0221748178  0.025322754  0.019755369
## 12  0.1894356505 -0.167405618 -0.203910662
## 13  0.3137416001 -0.335266154 -0.296248797
## 14 -0.0969427761  0.062028386  0.137785229
## 15  0.0843787510 -0.128835461 -0.006914942
## 16 -0.0531420869  0.028468182  0.086313818
## 17 -0.0271836261  0.008889032  0.049759567
## 18  0.0227872585 -0.044844187  0.014698315
## 19 -0.1140684195  0.146626191  0.059379069
## 20 -0.0200956838  0.034709112 -0.006903602
## 21 -0.0829693398  0.042055524  0.152053987
## 22  0.2620078051 -0.299442541 -0.185468011
## 23  0.0546306003 -0.092463785  0.006968177
## 24 -0.3623565160  0.329834636  0.346198714
## 25  0.0394488839 -0.048949485 -0.025740050
## 26  0.0816581713 -0.072640776 -0.081164117
## 27  0.0103635254 -0.012582384 -0.017184593
## 28  0.0419895172 -0.038892078 -0.038106780
## 29  0.0500352973 -0.049159176 -0.025153876
## 30 -0.0434351938  0.046540937  0.023406939
## 31  0.0372940235 -0.034009119 -0.055554804
## 32  0.3331825303 -0.345523841 -0.219245482
## 33 -0.0141526880  0.026249474 -0.032547183
## 34  0.0042654848  0.097322196 -0.356471323&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dffits(model3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           1           2           3           4           5           6           7           8           9          10          11          12          13          14          15          16          17          18          19          20          21          22          23          24          25          26          27          28          29          30          31          32          33          34 
## -0.49779546 -0.03443304  0.16617790  0.04839027  0.14501981  0.44419213  0.33617659  0.56641172  0.31345118  0.41159699  0.04146285  0.22201280 -0.44522486 -0.23142890 -0.29739864 -0.15570300 -0.11812321 -0.13975284  0.25511469  0.09211577 -0.24640080 -0.38190475 -0.25074744 -0.42548793 -0.08385349  0.10043884 -0.05588462  0.04905946  0.09917484 -0.05960708 -0.07911715  0.39982748 -0.11165807 -0.84678558&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;covratio(model3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         1         2         3         4         5         6         7         8         9        10        11        12        13        14        15        16        17        18        19        20        21        22        23        24        25        26        27        28        29        30        31        32        33        34 
## 0.9574605 1.1547079 1.0921820 1.2385180 1.3371269 0.7961237 0.8353191 0.6995172 0.9125707 1.0128230 1.1539505 1.3310018 0.9160657 1.0844138 1.0454007 1.1426135 1.1328307 1.1483997 1.0673803 1.1869404 1.2046850 1.0766525 1.0611755 1.0340267 1.1504192 1.1956712 1.1300346 1.2095848 1.1293150 1.3202770 1.1742902 1.2615329 1.3150607 1.1644730&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cooks.distance(model3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            1            2            3            4            5            6            7            8            9           10           11           12           13           14           15           16           17           18           19           20           21           22           23           24           25           26           27           28           29           30           31           32           33           34 
## 0.0788589481 0.0004080564 0.0093327348 0.0008060524 0.0072212533 0.0599828648 0.0350811487 0.0931782892 0.0313433979 0.0550406641 0.0005914727 0.0168582238 0.0626669338 0.0179583880 0.0292469522 0.0082568244 0.0047647510 0.0066653796 0.0217040047 0.0029131770 0.0206141656 0.0481191084 0.0209511332 0.0590048734 0.0024118042 0.0034625093 0.0010724176 0.0008283478 0.0033637037 0.0012230834 0.0021499446 0.0537957394 0.0042854350 0.2295447363&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;visualizing-more-complicated-relationships&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Visualizing more complicated relationships&lt;/h2&gt;
&lt;p&gt;So far, we cannot say with certainty that the additive model is the best fitting model. Before we commit to another analysis, it is important to take a step back and think about the visualization of the data to be better informed about what has occurred. Another reason for doing this is to be able to better interpret the observed results about the model assumptions (i.e., influential observations, some unhidden spatial structure in the data collection process).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Start with temperature, let&amp;#39;s add to the graph infomration about the lots
temp &amp;lt;- ggplot(aphids_data, aes(x=temperature, y=aphids, label=lot))
temp + geom_point() + geom_text(hjust=0.5, nudge_y=3) #Have a look a few of the observations like 30, 32, 33, 34 and also 8 (maybe 9)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/multiple_regression_files/figure-html/visualization-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Now let&amp;#39;s consider RH and do the same thing
temp2 &amp;lt;- ggplot(aphids_data, aes(x=humidity, y=aphids, label=lot))
temp2 + geom_point() + geom_text(hjust=0.5, nudge_y=3) #Maybe a bit different grouping&amp;quot; 6-9, 33 and 34&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/multiple_regression_files/figure-html/visualization-2.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# In 3-dimensiones? This example comes from the package *scatterplot3d*

with(aphids_data, scatterplot3d(temperature, humidity, aphids, angle=75)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/multiple_regression_files/figure-html/visualization-3.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;multiple-regression-with-interactions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Multiple regression with interactions&lt;/h2&gt;
&lt;p&gt;Given that individually, we see different relationships between the number of aphids with temperature or relative humidity, we might want to consider if there is an interaction between those two factors that helps to explain the overall relationship.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model4 &amp;lt;- with(aphids_data, lm(aphids ~ temperature + humidity + temperature:humidity))

anova(model4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Response: aphids
##                      Df  Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## temperature           1 15194.8 15194.8  33.506 2.522e-06 ***
## humidity              1  4813.1  4813.1  10.613  0.002789 ** 
## temperature:humidity  1  2764.0  2764.0   6.095  0.019474 *  
## Residuals            30 13604.8   453.5                      
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(model4) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = aphids ~ temperature + humidity + temperature:humidity)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -41.13 -12.87  -2.02  10.25  41.75 
## 
## Coefficients:
##                       Estimate Std. Error t value Pr(&amp;gt;|t|)  
## (Intercept)          150.70989   68.02395   2.216   0.0345 *
## temperature           -4.72276    2.11121  -2.237   0.0329 *
## humidity              -1.29670    1.11576  -1.162   0.2543  
## temperature:humidity   0.09728    0.03940   2.469   0.0195 *
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 21.3 on 30 degrees of freedom
## Multiple R-squared:  0.626,  Adjusted R-squared:  0.5886 
## F-statistic: 16.74 on 3 and 30 DF,  p-value: 1.414e-06&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(model4)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/multiple_regression_files/figure-html/interaction-1.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;/post/multiple_regression_files/figure-html/interaction-2.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;/post/multiple_regression_files/figure-html/interaction-3.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;/post/multiple_regression_files/figure-html/interaction-4.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Assumptions = values, model4
rstudent(model4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           1           2           3           4           5           6           7           8           9          10          11          12          13          14          15          16          17          18          19          20          21          22          23          24          25          26          27          28          29          30          31          32          33          34 
## -1.67738460 -0.48588149  0.45590218 -0.19523576 -0.14531052  1.79972032  1.58449094  2.15886689  1.30727332  1.70840183 -0.02181518  0.36068272 -2.12994645 -0.86808331 -0.85354897 -0.38866846 -0.45693592 -0.18387477  1.23775270  0.97153371  0.27052672 -1.03205411 -0.82508336 -1.86536030 -0.40145315  0.04498291 -0.68446574 -0.24802524  0.13423194 -0.06323885 -0.67115336  0.75218833  0.56505021  0.02067808&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dfbetas(model4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      (Intercept)  temperature     humidity temperature:humidity
## 1  -0.0949334782  0.104709362 -0.039584196          0.019350004
## 2  -0.0434083991  0.051676363  0.047346765         -0.063039334
## 3   0.0104511179 -0.020483667 -0.043004153          0.068644149
## 4   0.0125973436 -0.003428996  0.005585795         -0.027700059
## 5   0.0200060874 -0.009982149  0.004443134         -0.028864368
## 6   0.3651795277 -0.341307478 -0.317703892          0.249350618
## 7   0.2422524883 -0.242541747 -0.242297450          0.232776103
## 8  -0.0109075193 -0.042140260 -0.177929199          0.320976539
## 9   0.0498830523 -0.072826504 -0.129655838          0.189283832
## 10 -0.3408072725  0.358785369  0.217261311         -0.151702669
## 11  0.0005263790 -0.000316099  0.001062068         -0.002009342
## 12  0.1221549093 -0.098424293 -0.075269257          0.020228157
## 13  0.1333989598 -0.088122021  0.090421220         -0.242562866
## 14 -0.0418864697  0.008011790  0.011031748          0.038058296
## 15  0.1317295973 -0.158260224 -0.117120422          0.123141864
## 16  0.0004605123 -0.017956896 -0.015762200          0.038604856
## 17 -0.0058300098 -0.008533870 -0.000619253          0.017463648
## 18  0.0260840050 -0.032918740 -0.025833607          0.029557943
## 19 -0.1563373872  0.174924757  0.097882894         -0.076671310
## 20 -0.2133463221  0.258866254  0.220017614         -0.243411245
## 21 -0.0520591385  0.077908687  0.084254567         -0.115605524
## 22  0.2314600667 -0.237322197 -0.139947666          0.086596590
## 23  0.0925507109 -0.115811898 -0.079585871          0.087209322
## 24 -0.5799971247  0.525151313  0.447129697         -0.289295996
## 25  0.0304683047 -0.032541539 -0.007414919         -0.003043043
## 26  0.0122044840 -0.010813140 -0.009331422          0.005713728
## 27 -0.0499259797  0.058126678  0.078027579         -0.098076089
## 28 -0.0786659661  0.072746679  0.061679949         -0.042751118
## 29  0.0246830038 -0.024958336 -0.021748326          0.020466850
## 30 -0.0135483304  0.012244012  0.001928902          0.002110430
## 31 -0.0027225130  0.024986567  0.044656549         -0.096290927
## 32  0.2502942582 -0.232060720 -0.113674644          0.047457190
## 33 -0.1102356148  0.113536109  0.212046646         -0.197252978
## 34 -0.0122551182  0.012733935  0.018960381         -0.017832210&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dffits(model4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            1            2            3            4            5            6            7            8            9           10           11           12           13           14           15           16           17           18           19           20           21           22           23           24           25           26           27           28           29           30           31           32           33           34 
## -0.531609206 -0.125502391  0.122090070 -0.074914358 -0.075725395  0.474770847  0.377244053  0.613987196  0.327877853  0.546849311 -0.005271111  0.175211526 -0.630865880 -0.225538194 -0.260429456 -0.111153445 -0.107334987 -0.057484681  0.327640435  0.381923652  0.159601123 -0.354887689 -0.224599512 -0.679748019 -0.094906727  0.015111134 -0.160394451 -0.089969303  0.035517257 -0.028285597 -0.207379175  0.361507505  0.332123809  0.023506774&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;covratio(model4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         1         2         3         4         5         6         7         8         9        10        11        12        13        14        15        16        17        18        19        20        21        22        23        24        25        26        27        28        29        30        31        32        33        34 
## 0.8701623 1.1826549 1.1927973 1.3069641 1.4520128 0.8020052 0.8681666 0.6819798 0.9680977 0.8603410 1.2120133 1.3903653 0.6965068 1.1033099 1.1335691 1.2134151 1.1742397 1.2513168 0.9974108 1.1632187 1.5283511 1.1085842 1.1210624 0.8245063 1.1827248 1.2741137 1.1331044 1.2849849 1.2223690 1.3735892 1.1795590 1.3049070 1.4748564 2.6250656&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cooks.distance(model4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            1            2            3            4            5            6            7            8            9           10           11           12           13           14           15           16           17           18           19           20           21           22           23           24           25           26           27           28           29           30           31           32           33           34 
## 6.662438e-02 4.040602e-03 3.827564e-03 1.449516e-03 1.481939e-03 5.243821e-02 3.387265e-02 8.399563e-02 2.625550e-02 7.026714e-02 7.185558e-06 7.903960e-03 8.900520e-02 1.282220e-02 1.711070e-02 3.178723e-03 2.958219e-03 8.536139e-04 2.636942e-02 3.653477e-02 6.571137e-03 3.141810e-02 1.274688e-02 1.066957e-01 2.316596e-03 5.905097e-05 6.547598e-03 2.088968e-03 3.260411e-04 2.068874e-04 1.095216e-02 3.315175e-02 2.821681e-02 1.429035e-04&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Graphically from olsrr package
ols_plot_resid_stud(model4)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/multiple_regression_files/figure-html/interaction-5.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ols_plot_dfbetas(model4)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/multiple_regression_files/figure-html/interaction-6.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ols_plot_dffits(model4)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/multiple_regression_files/figure-html/interaction-7.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ols_plot_cooksd_chart(model4)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/multiple_regression_files/figure-html/interaction-8.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Compare the different models
anova(model1, model3) # model 3 better&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Model 1: aphids ~ temperature
## Model 2: aphids ~ temperature + humidity
##   Res.Df   RSS Df Sum of Sq      F   Pr(&amp;gt;F)   
## 1     32 21182                                
## 2     31 16369  1    4813.1 9.1151 0.005038 **
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anova(model2, model3) # model 2 mejor (only RH)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Model 1: aphids ~ humidity
## Model 2: aphids ~ temperature + humidity
##   Res.Df   RSS Df Sum of Sq      F Pr(&amp;gt;F)
## 1     32 16486                           
## 2     31 16369  1    117.18 0.2219 0.6409&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anova(model2, model4) # the interaction improved the model?&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Model 1: aphids ~ humidity
## Model 2: aphids ~ temperature + humidity + temperature:humidity
##   Res.Df   RSS Df Sum of Sq      F  Pr(&amp;gt;F)  
## 1     32 16486                              
## 2     30 13605  2    2881.2 3.1767 0.05606 .
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anova(model3, model4) # the interaction improved the model&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Model 1: aphids ~ temperature + humidity
## Model 2: aphids ~ temperature + humidity + temperature:humidity
##   Res.Df   RSS Df Sum of Sq     F  Pr(&amp;gt;F)  
## 1     31 16369                             
## 2     30 13605  1      2764 6.095 0.01947 *
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Remember that once we have a model selected, we should examine the assumptions in greater detail&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;predictions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Predictions&lt;/h2&gt;
&lt;p&gt;To close our discussion, let’s again look at the function &lt;em&gt;predict&lt;/em&gt; using model 4.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Let&amp;#39;s start by considering the average values for temperature and relative humidity
mean(temperature)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 28.08529&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(humidity)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 35.19118&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;observation &amp;lt;- data.frame(temperature=mean(temperature), humidity=mean(humidity))

predict(object=model4, newdata=observation, interval=&amp;quot;confidence&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        fit      lwr      upr
## 1 68.58645 59.30643 77.86646&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;predict(object=model4, newdata=observation, interval=&amp;quot;predict&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        fit      lwr      upr
## 1 68.58645 24.11635 113.0565&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Looking at all observations in the database
intervals&amp;lt;-predict(model4, interval=&amp;quot;confidence&amp;quot;)
intervals&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            fit        lwr       upr
## 1   94.0665692  80.927158 107.20598
## 2   87.1482874  76.271599  98.02498
## 3   77.4955105  66.245093  88.74593
## 4   96.9454425  81.365016 112.52587
## 5  100.7900752  80.691122 120.88903
## 6   64.2519748  53.158443  75.34551
## 7   71.9715847  61.898562  82.04461
## 8   76.2533767  64.356209  88.15054
## 9   75.3109441  64.730640  85.89125
## 10  40.4082060  27.149656  53.66676
## 11  63.4592842  53.244672  73.67390
## 12  35.9887485  16.985340  54.99216
## 13  68.1334763  55.782306  80.48465
## 14  36.9661205  26.029726  47.90252
## 15  31.4646380  18.772561  44.15671
## 16  31.0728691  19.114485  43.03125
## 17  39.6002445  29.654831  49.54566
## 18  28.7989865  15.821797  41.77618
## 19  41.7421198  30.613084  52.87116
## 20  20.7271297   4.815514  36.63875
## 21   0.9596999 -21.139235  23.05864
## 22  41.7610595  27.618756  55.90336
## 23  35.0445138  23.621299  46.46773
## 24  58.8698369  43.979310  73.76036
## 25  50.4385954  40.432771  60.44442
## 26  55.0764466  41.227039  68.92585
## 27  74.3189517  64.396268  84.24164
## 28  64.0447598  49.214277  78.87524
## 29  79.1902050  68.065480  90.31493
## 30  90.2502594  72.492852 108.00767
## 31  90.7822943  77.942971 103.62162
## 32  87.4570502  68.617765 106.29634
## 33  97.5065531  75.468470 119.54464
## 34  96.7041862  64.049441 129.35893&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;predictions&amp;lt;-predict(model4, interval=&amp;quot;predict&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in predict.lm(model4, interval = &amp;quot;predict&amp;quot;): predictions on current data refer to _future_ responses&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;predictions&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            fit        lwr       upr
## 1   94.0665692  48.634034 139.49910
## 2   87.1482874  42.317791 131.97878
## 3   77.4955105  32.572877 122.41814
## 4   96.9454425  50.747815 143.14307
## 5  100.7900752  52.879335 148.70082
## 6   64.2519748  19.368375 109.13557
## 7   71.9715847  27.329263 116.61391
## 8   76.2533767  31.164423 121.34233
## 9   75.3109441  30.551432 120.07046
## 10  40.4082060  -5.058928  85.87534
## 11  63.4592842  18.784802 108.13377
## 12  35.9887485 -11.472822  83.45032
## 13  68.1334763  22.922609 113.34434
## 14  36.9661205  -7.878900  81.81114
## 15  31.4646380 -13.840548  76.76982
## 16  31.0728691 -14.032275  76.17801
## 17  39.6002445  -5.013457  84.21395
## 18  28.7989865 -16.586898  74.18487
## 19  41.7421198  -3.150269  86.63451
## 20  20.7271297 -25.583243  67.03750
## 21   0.9596999 -47.823843  49.74324
## 22  41.7610595  -3.971597  87.49372
## 23  35.0445138  -9.921706  80.01073
## 24  58.8698369  12.900294 104.83938
## 25  50.4385954   5.811388  95.06580
## 26  55.0764466   9.433515 100.71938
## 27  74.3189517  29.710312 118.92759
## 28  64.0447598  18.094631 109.99489
## 29  79.1902050  34.298885 124.08152
## 30  90.2502594  43.273705 137.22681
## 31  90.7822943  45.435637 136.12895
## 32  87.4570502  40.060956 134.85314
## 33  97.5065531  48.750546 146.26256
## 34  96.7041862  42.318494 151.08988&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;summary&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;The objective in this exercise was to introduce the concept of using multiple regression to build a model. This provides a base also as you move forward in your modeling work to think about things like &lt;em&gt;hidden interactions&lt;/em&gt;, which is often very common in complex datasets and can often drive aspects of things like machine learning.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Polynomial regression</title>
      <link>/post/polynomial_regression/</link>
      <pubDate>Thu, 01 Aug 2019 21:08:07 -0500</pubDate>
      
      <guid>/post/polynomial_regression/</guid>
      <description>


&lt;div id=&#34;background&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt;In many studies, for example if one looks the relationship between nitrogen and yield for many cereal crops, the relationship is not linear, rather there is often a plateau where after a specific amount, the response decreases. A simpler linear-type model will explain some of the variability, but not very well. In these situations we can consider a polynomial form to the model.&lt;/p&gt;
&lt;p&gt;We can define this relationship in general terms as the the relation betweeen the independent variable, &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;, and the expected response, &lt;span class=&#34;math inline&#34;&gt;\(E(y|x)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Note: Very important with this type of analysis is to understand the software that you are using since often we focus on use &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(X^2\)&lt;/span&gt;, which depending on how those variables are defined, leads to high collinearity. This example illustrates that concept and provides methods to overcome the issue.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(Hmisc)
library(corrplot)
library(readr)
library(HH)
library(car)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;For this example, we have the following situation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Density = Seeding density (number of plants per &lt;span class=&#34;math inline&#34;&gt;\(m^2\)&lt;/span&gt;)&lt;/li&gt;
&lt;li&gt;Yield = quantity of biomass&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;density &amp;lt;- rep(c(10,20,30,40,50), each=3)
yield &amp;lt;- c(12.2, 11.4, 12.4, 16, 15.5, 16.5, 18.6, 20.2, 18.2, 17.6, 19.3, 17.1, 18, 16.4, 16.6)

densities &amp;lt;- data.frame(density, yield)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-regression&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear regression&lt;/h2&gt;
&lt;p&gt;To start, we will build a simple linear regression models and examine the overall model fit, including model assumptions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model1 &amp;lt;- lm(yield~density)
anova(model1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Response: yield
##           Df Sum Sq Mean Sq F value   Pr(&amp;gt;F)   
## density    1  43.20  43.200  10.825 0.005858 **
## Residuals 13  51.88   3.991                    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(model1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = yield ~ density)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
##   -2.6   -1.7    0.0    1.5    3.8 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 12.80000    1.20966   10.58  9.3e-08 ***
## density      0.12000    0.03647    3.29  0.00586 ** 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 1.998 on 13 degrees of freedom
## Multiple R-squared:  0.4544, Adjusted R-squared:  0.4124 
## F-statistic: 10.82 on 1 and 13 DF,  p-value: 0.005858&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(model1) # You hopefully can see that the model fit is not very good&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/polynomial_regression_files/figure-html/lineal-1.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/post/polynomial_regression_files/figure-html/lineal-2.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/post/polynomial_regression_files/figure-html/lineal-3.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/post/polynomial_regression_files/figure-html/lineal-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ci.plot(model1) # It should be obvious that the regression line does not reflect the actual relationship well&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/polynomial_regression_files/figure-html/lineal-5.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;quadratic-regression-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Quadratic regression 1&lt;/h2&gt;
&lt;p&gt;Given the result just seem with the simple linear regression, we will construct a quadratic model. The structure of the analysis is the same, but we will create a variable for &lt;em&gt;density&lt;/em&gt; to reflect the squared term, &lt;span class=&#34;math inline&#34;&gt;\(density^2\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Define the density as a squared term (there are multiple ways to do this, but we will use a simple approach for now)

density2&amp;lt;-density^2

model2&amp;lt;-lm(yield~density + density2)

# Significance
anova(model2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Response: yield
##           Df Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## density    1  43.20  43.200  52.470 1.024e-05 ***
## density2   1  42.00  42.000  51.012 1.177e-05 ***
## Residuals 12   9.88   0.823                      
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(model2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = yield ~ density + density2)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
##  -1.50  -0.50  -0.20   0.35   1.80 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  5.80000    1.12359   5.162 0.000236 ***
## density      0.72000    0.08563   8.409 2.25e-06 ***
## density2    -0.01000    0.00140  -7.142 1.18e-05 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.9074 on 12 degrees of freedom
## Multiple R-squared:  0.8961, Adjusted R-squared:  0.8788 
## F-statistic: 51.74 on 2 and 12 DF,  p-value: 1.259e-06&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Assumptions
plot(model2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/polynomial_regression_files/figure-html/quadratic1-1.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/post/polynomial_regression_files/figure-html/quadratic1-2.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/post/polynomial_regression_files/figure-html/quadratic1-3.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/post/polynomial_regression_files/figure-html/quadratic1-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Let&amp;#39;s focus on comparing the two models based on Cook&amp;#39;s Distance.
plot(model1, which=4) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/polynomial_regression_files/figure-html/quadratic1-5.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(model2, which=4) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/polynomial_regression_files/figure-html/quadratic1-6.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# F-test between model 1 and model 2
anova(model1, model2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Model 1: yield ~ density
## Model 2: yield ~ density + density2
##   Res.Df   RSS Df Sum of Sq      F    Pr(&amp;gt;F)    
## 1     13 51.88                                  
## 2     12  9.88  1        42 51.012 1.177e-05 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Additional tools to understand the model fit and model assumptions for the quadratic form
influence.measures(model2) # this is a general function to create the base for subsequent measurments&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Influence measures of
##   lm(formula = yield ~ density + density2) :
## 
##       dfb.1_ dfb.dnst dfb.dns2   dffit cov.r  cook.d   hat inf
## 1   1.46e-01  -0.1121   0.0927  0.1632 1.811 0.00963 0.295   *
## 2  -4.47e-01   0.3445  -0.2847 -0.5012 1.571 0.08663 0.295    
## 3   2.94e-01  -0.2262   0.1870  0.3292 1.718 0.03850 0.295    
## 4   3.67e-17  -0.0280   0.0373 -0.0849 1.461 0.00261 0.124    
## 5   5.03e-17  -0.1007   0.1339 -0.3054 1.244 0.03199 0.124    
## 6  -3.68e-17   0.0422  -0.0560  0.1278 1.436 0.00588 0.124    
## 7  -5.44e-02   0.0764  -0.0779  0.1016 1.527 0.00373 0.162    
## 8  -6.26e-01   0.8795  -0.8964  1.1687 0.349 0.30236 0.162    
## 9   5.44e-02  -0.0764   0.0779 -0.1016 1.527 0.00373 0.162    
## 10  2.07e-01  -0.2391   0.1976 -0.4506 1.025 0.06529 0.124    
## 11 -1.40e-01   0.1620  -0.1339  0.3054 1.244 0.03199 0.124    
## 12  3.39e-01  -0.3920   0.3240 -0.7388 0.601 0.14691 0.124    
## 13  3.26e-01  -0.4683   0.6225  1.0961 0.919 0.34654 0.295    
## 14 -9.79e-02   0.1406  -0.1870 -0.3292 1.718 0.03850 0.295    
## 15 -4.85e-02   0.0697  -0.0927 -0.1632 1.811 0.00963 0.295   *&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dffits(model2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           1           2           3           4           5           6 
##  0.16317088 -0.50123382  0.32920738 -0.08494387 -0.30538465  0.12778710 
##           7           8           9          10          11          12 
##  0.10156307  1.16874641 -0.10156307 -0.45055886  0.30538465 -0.73883264 
##          13          14          15 
##  1.09610758 -0.32920738 -0.16317088&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dfbeta(model2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      (Intercept)      density      density2
## 1   1.702703e-01 -0.010000000  1.351351e-04
## 2  -5.108108e-01  0.030000000 -4.054054e-04
## 3   3.405405e-01 -0.020000000  2.702703e-04
## 4   4.299875e-17 -0.002500000  5.434783e-05
## 5   5.733167e-17 -0.008750000  1.902174e-04
## 6  -4.299875e-17  0.003750000 -8.152174e-05
## 7  -6.363636e-02  0.006818182 -1.136364e-04
## 8  -5.727273e-01  0.061363636 -1.022727e-03
## 9   6.363636e-02 -0.006818182  1.136364e-04
## 10  2.282609e-01 -0.020108696  2.717391e-04
## 11 -1.597826e-01  0.014076087 -1.902174e-04
## 12  3.423913e-01 -0.030163043  4.076087e-04
## 13  3.405405e-01 -0.037297297  8.108108e-04
## 14 -1.135135e-01  0.012432432 -2.702703e-04
## 15 -5.675676e-02  0.006216216 -1.351351e-04&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;covratio(model2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         1         2         3         4         5         6         7 
## 1.8105775 1.5709359 1.7180496 1.4612786 1.2440860 1.4359881 1.5267335 
##         8         9        10        11        12        13        14 
## 0.3493908 1.5267335 1.0252651 1.2440860 0.6006431 0.9193090 1.7180496 
##        15 
## 1.8105775&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cooks.distance(model2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           1           2           3           4           5           6 
## 0.009626105 0.086634944 0.038504420 0.002611680 0.031993085 0.005876281 
##           7           8           9          10          11          12 
## 0.003732810 0.302357630 0.003732810 0.065292011 0.031993085 0.146907024 
##          13          14          15 
## 0.346539778 0.038504420 0.009626105&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;vif(model2) # 26.71 is the value, values greater than 10 typically indicate high collinearity&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  density density2 
## 26.71429 26.71429&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;quadratic-regression-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Quadratic regression 2&lt;/h2&gt;
&lt;p&gt;Given the result for the first quadratic regression that indicated high collinearity for &lt;span class=&#34;math inline&#34;&gt;\(density\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(density^2\)&lt;/span&gt;, what we can do to remove this without affecting the analysis is to center the &lt;em&gt;density&lt;/em&gt; variable and then run the analysis again. This is a very common practice to reduce the impact of not only high collinearity but also for cases for things like multivariate statistics where the scale for individual response variables can have high leverage on the overall analysis. The fuction, &lt;em&gt;scale&lt;/em&gt;, allows us to the scale the density considering the mean value (we are not taking into account the variance, which is another common approach = location-scale type centering).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Center and standardize the density variable

# This approach substracts the mean, scale=FALSE tells R that we do not take into account the standard deviation in the analysis
den_centered&amp;lt;-scale(density, center=TRUE, scale=FALSE) 

# The same if we did this by &amp;quot;hand&amp;quot;
density-mean(density)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] -20 -20 -20 -10 -10 -10   0   0   0  10  10  10  20  20  20&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Create a new variable for density^2 based on centered values
den_centered2 &amp;lt;- den_centered^2

plot(den_centered, den_centered2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/polynomial_regression_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Regression model with centered data

model3&amp;lt;-lm(yield~den_centered+den_centered2)
anova(model3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Response: yield
##               Df Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## den_centered   1  43.20  43.200  52.470 1.024e-05 ***
## den_centered2  1  42.00  42.000  51.012 1.177e-05 ***
## Residuals     12   9.88   0.823                      
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(model3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = yield ~ den_centered + den_centered2)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
##  -1.50  -0.50  -0.20   0.35   1.80 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)   18.40000    0.36511  50.396 2.44e-15 ***
## den_centered   0.12000    0.01657   7.244 1.02e-05 ***
## den_centered2 -0.01000    0.00140  -7.142 1.18e-05 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.9074 on 12 degrees of freedom
## Multiple R-squared:  0.8961, Adjusted R-squared:  0.8788 
## F-statistic: 51.74 on 2 and 12 DF,  p-value: 1.259e-06&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Assumptions
plot(model3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/polynomial_regression_files/figure-html/unnamed-chunk-1-2.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/post/polynomial_regression_files/figure-html/unnamed-chunk-1-3.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/post/polynomial_regression_files/figure-html/unnamed-chunk-1-4.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/post/polynomial_regression_files/figure-html/unnamed-chunk-1-5.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Compare original model with the centered quadratic model
anova(model1, model3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Model 1: yield ~ density
## Model 2: yield ~ den_centered + den_centered2
##   Res.Df   RSS Df Sum of Sq      F    Pr(&amp;gt;F)    
## 1     13 51.88                                  
## 2     12  9.88  1        42 51.012 1.177e-05 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Collinearity?
dffits(model3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           1           2           3           4           5           6 
##  0.16317088 -0.50123382  0.32920738 -0.08494387 -0.30538465  0.12778710 
##           7           8           9          10          11          12 
##  0.10156307  1.16874641 -0.10156307 -0.45055886  0.30538465 -0.73883264 
##          13          14          15 
##  1.09610758 -0.32920738 -0.16317088&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dfbeta(model3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     (Intercept)  den_centered den_centered2
## 1  -0.008108108 -1.891892e-03  1.351351e-04
## 2   0.024324324  5.675676e-03 -4.054054e-04
## 3  -0.016216216 -3.783784e-03  2.702703e-04
## 4  -0.026086957  7.608696e-04  5.434783e-05
## 5  -0.091304348  2.663043e-03  1.902174e-04
## 6   0.039130435 -1.141304e-03 -8.152174e-05
## 7   0.038636364  7.647245e-20 -1.136364e-04
## 8   0.347727273  9.416246e-19 -1.022727e-03
## 9  -0.038636364  1.769001e-19  1.136364e-04
## 10 -0.130434783 -3.804348e-03  2.717391e-04
## 11  0.091304348  2.663043e-03 -1.902174e-04
## 12 -0.195652174 -5.706522e-03  4.076087e-04
## 13 -0.048648649  1.135135e-02  8.108108e-04
## 14  0.016216216 -3.783784e-03 -2.702703e-04
## 15  0.008108108 -1.891892e-03 -1.351351e-04&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;covratio(model3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         1         2         3         4         5         6         7 
## 1.8105775 1.5709359 1.7180496 1.4612786 1.2440860 1.4359881 1.5267335 
##         8         9        10        11        12        13        14 
## 0.3493908 1.5267335 1.0252651 1.2440860 0.6006431 0.9193090 1.7180496 
##        15 
## 1.8105775&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cooks.distance(model3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           1           2           3           4           5           6 
## 0.009626105 0.086634944 0.038504420 0.002611680 0.031993085 0.005876281 
##           7           8           9          10          11          12 
## 0.003732810 0.302357630 0.003732810 0.065292011 0.031993085 0.146907024 
##          13          14          15 
## 0.346539778 0.038504420 0.009626105&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;vif(model3) #The value is now = 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  den_centered den_centered2 
##             1             1&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;what-occurred&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What occurred?&lt;/h2&gt;
&lt;p&gt;We will take a look at the correlations between the original forms for density and centered forms.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor(density, density2) #high correlation = collinearity&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.9811049&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor(den_centered, den_centered2) #no correlation&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1]
## [1,]    0&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;summary-and-considerations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Summary and considerations&lt;/h2&gt;
&lt;p&gt;The goal of this exercise was to illustrate how one needs to check any &lt;em&gt;package&lt;/em&gt; or &lt;em&gt;software&lt;/em&gt; regarding assumptions on linear, quadratic, higher polynomial terms. This becomes very important as you consider working with centered or standardized variables.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Nonlinear regression</title>
      <link>/post/nonlinear_regression/</link>
      <pubDate>Thu, 01 Aug 2019 21:08:06 -0500</pubDate>
      
      <guid>/post/nonlinear_regression/</guid>
      <description>


&lt;div id=&#34;background&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt;Many times, we are interested in estimating the relationship between different variables that has a general form described as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(x) = E[Y|X=x]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Where we do not have a specific function type defined (i.e., specific model):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = f(X) + e\]&lt;/span&gt;
As such, we would like to describe the data using the most appropriate model and estimate the parameters. In this introductory exercise, we will use nonparametric methods to do such a task and focus on three possible methods:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Moving average = calculate the mean value, &lt;em&gt;Y&lt;/em&gt;, around a window of &lt;em&gt;X&lt;/em&gt; values&lt;/li&gt;
&lt;li&gt;Weighted moving averages = kernel smoothing: weight data as a function of distance, i.e., points closer in space are given greater weight&lt;/li&gt;
&lt;li&gt;Local polynomial regression: adjust the polynomial value based on least squares methods for observations in a local window (weighted by distance)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Packages&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(Hmisc)
library(corrplot)
library(readr)
library(HH)
library(car)
library(scatterplot3d)
library(leaps)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;For this example, we are using a database called &lt;em&gt;Emissions&lt;/em&gt;. This data comes from FAO and represents the amount of &lt;span class=&#34;math inline&#34;&gt;\(CO~2\)&lt;/span&gt; emitted in different countries from Mexico to Panama. The number of years of data collection was 21. The data are also standardized based on the area under agricultural production. Given that one of the authors of this worked in Costa Rica, we will use that as our data source for the exercise. This will required working with a database that is in .csv format and then subset out the part that relates to Costa Rica. To accomplish this first part, we will using coding based on &lt;em&gt;tidyverse&lt;/em&gt;, especially using &lt;em&gt;dplyr&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Please note: I have located the data in my local &lt;em&gt;Document&lt;/em&gt; folder for eash of reading this into R. You can change the location accordingly for your personal use. If you are using this as a script, you can also use the import options in RStudio.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;emissions &amp;lt;- read_csv(&amp;quot;Emissions.csv&amp;quot;)
head(emissions)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 5
##   Country  Year   Area   CO2  CO2_area
##   &amp;lt;chr&amp;gt;   &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
## 1 Belize      1 128277  7.31 0.000057 
## 2 Belize      2 153923  7.31 0.0000475
## 3 Belize      3 164124  7.31 0.0000445
## 4 Belize      4 184274  7.31 0.0000397
## 5 Belize      5 130610  5.85 0.0000448
## 6 Belize      6 173667  6.33 0.0000365&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Quick summary of the results across the countries

summaries &amp;lt;- emissions %&amp;gt;% group_by(Country)
summaries %&amp;gt;% str()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Classes &amp;#39;grouped_df&amp;#39;, &amp;#39;tbl_df&amp;#39;, &amp;#39;tbl&amp;#39; and &amp;#39;data.frame&amp;#39;:  168 obs. of  5 variables:
##  $ Country : chr  &amp;quot;Belize&amp;quot; &amp;quot;Belize&amp;quot; &amp;quot;Belize&amp;quot; &amp;quot;Belize&amp;quot; ...
##  $ Year    : num  1 2 3 4 5 6 7 8 9 10 ...
##  $ Area    : num  128277 153923 164124 184274 130610 ...
##  $ CO2     : num  7.31 7.31 7.31 7.31 5.85 ...
##  $ CO2_area: num  5.70e-05 4.75e-05 4.45e-05 3.97e-05 4.48e-05 3.65e-05 2.96e-05 3.36e-05 5.15e-05 5.60e-05 ...
##  - attr(*, &amp;quot;spec&amp;quot;)=
##   .. cols(
##   ..   Country = col_character(),
##   ..   Year = col_double(),
##   ..   Area = col_double(),
##   ..   CO2 = col_double(),
##   ..   CO2_area = col_double()
##   .. )
##  - attr(*, &amp;quot;groups&amp;quot;)=Classes &amp;#39;tbl_df&amp;#39;, &amp;#39;tbl&amp;#39; and &amp;#39;data.frame&amp;#39;:   8 obs. of  2 variables:
##   ..$ Country: chr  &amp;quot;Belize&amp;quot; &amp;quot;CostaRica&amp;quot; &amp;quot;ElSalvador&amp;quot; &amp;quot;Guatemala&amp;quot; ...
##   ..$ .rows  :List of 8
##   .. ..$ : int  1 2 3 4 5 6 7 8 9 10 ...
##   .. ..$ : int  22 23 24 25 26 27 28 29 30 31 ...
##   .. ..$ : int  43 44 45 46 47 48 49 50 51 52 ...
##   .. ..$ : int  64 65 66 67 68 69 70 71 72 73 ...
##   .. ..$ : int  85 86 87 88 89 90 91 92 93 94 ...
##   .. ..$ : int  106 107 108 109 110 111 112 113 114 115 ...
##   .. ..$ : int  127 128 129 130 131 132 133 134 135 136 ...
##   .. ..$ : int  148 149 150 151 152 153 154 155 156 157 ...
##   ..- attr(*, &amp;quot;.drop&amp;quot;)= logi TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summaries %&amp;gt;% summarise(
  em_mean = mean(CO2_area),
  em_sd = sd(CO2_area),
  em_cv = sd(CO2_area)/mean(CO2_area)*100,
  em_max = max(CO2_area),
  em_min = min(CO2_area)
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8 x 6
##   Country      em_mean     em_sd em_cv    em_max    em_min
##   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
## 1 Belize     0.000106  0.000147  139.  0.000668  0.0000296
## 2 CostaRica  0.000415  0.000100   24.2 0.000649  0.000232 
## 3 ElSalvador 0.000139  0.0000280  20.2 0.000196  0.0000983
## 4 Guatemala  0.000142  0.0000239  16.8 0.000172  0.000099 
## 5 Honduras   0.000125  0.0000740  59.4 0.000281  0.0000224
## 6 Mexico     0.000111  0.0000147  13.3 0.000131  0.0000843
## 7 Nicaragua  0.0000614 0.0000182  29.6 0.0000923 0.0000242
## 8 Panama     0.000119  0.0000285  23.9 0.000169  0.0000828&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Create a subset database to work with data only from Costa Rica
costa_rica &amp;lt;- filter(emissions, Country==&amp;quot;CostaRica&amp;quot;)
head(costa_rica)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 5
##   Country    Year   Area   CO2 CO2_area
##   &amp;lt;chr&amp;gt;     &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 CostaRica     1 773395  271. 0.00035 
## 2 CostaRica     2 783774  304. 0.000388
## 3 CostaRica     3 778918  317. 0.000407
## 4 CostaRica     4 740508  292. 0.000395
## 5 CostaRica     5 769340  341  0.000443
## 6 CostaRica     6 765005  341  0.000446&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;loess-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Loess 1&lt;/h2&gt;
&lt;p&gt;This the method based on local polynomial regression.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# What does the relationship look like?

CR &amp;lt;- ggplot(data=costa_rica, aes(x=Year, y=CO2_area))

CR + geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/nonlinear_regression_files/figure-html/loess-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;CR + geom_point() + geom_line()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/nonlinear_regression_files/figure-html/loess-2.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Loess

cr_np1 &amp;lt;- with(costa_rica, loess(CO2_area ~ Year , span=0.75)) #default method
summary(cr_np1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Call:
## loess(formula = CO2_area ~ Year, span = 0.75)
## 
## Number of Observations: 21 
## Equivalent Number of Parameters: 4.61 
## Residual Standard Error: 7.132e-05 
## Trace of smoother matrix: 5.06  (exact)
## 
## Control settings:
##   span     :  0.75 
##   degree   :  2 
##   family   :  gaussian
##   surface  :  interpolate      cell = 0.2
##   normalize:  TRUE
##  parametric:  FALSE
## drop.square:  FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;crnp1_pred &amp;lt;- predict(cr_np1, data.frame(Year=seq(1,21,0.5)))
pred1 &amp;lt;- data.frame(Year=seq(1,21,0.5), crnp1_pred)

# Graphically
ej1 &amp;lt;- ggplot() 
ej1 +
  geom_point(data=costa_rica, aes(x=Year, y=CO2_area)) +
  geom_line(data=costa_rica, aes(x=Year, y=CO2_area), lty=1) +
  geom_line(data=pred1, aes(x=Year, y=crnp1_pred), lty=2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/nonlinear_regression_files/figure-html/loess-3.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;modify-the-loess-line&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Modify the Loess line&lt;/h2&gt;
&lt;p&gt;Let’s look at some different line forms with Loess.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Span=0.5
cr_np2 &amp;lt;- with(costa_rica, loess(CO2_area ~ Year , span=0.5))
crnp2_pred &amp;lt;- predict(cr_np2, data.frame(Year=seq(1,21,0.5)))
pred2 &amp;lt;- data.frame(Year=seq(1,21,0.5), crnp2_pred)

ej1 &amp;lt;- ggplot() 
ej1 +
  geom_point(data=costa_rica, aes(x=Year, y=CO2_area)) +
  geom_line(data=costa_rica, aes(x=Year, y=CO2_area), lty=1) +
  geom_line(data=pred1, aes(x=Year, y=crnp1_pred), lty=2, lwd=1.5) +
  geom_line(data=pred2, aes(x=Year, y=crnp2_pred), lty=3, lwd=1.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/nonlinear_regression_files/figure-html/loess2-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Span=0.25
cr_np3 &amp;lt;- with(costa_rica, loess(CO2_area ~ Year, span=0.25))
crnp3_pred &amp;lt;- predict(cr_np3, data.frame(Year=seq(1,21,0.5)))
pred3 &amp;lt;- data.frame(Year=seq(1,21,0.5), crnp2_pred)

ej1 &amp;lt;- ggplot() 
ej1 +
  geom_point(data=costa_rica, aes(x=Year, y=CO2_area)) +
  geom_line(data=costa_rica, aes(x=Year, y=CO2_area), lty=1) +
  geom_line(data=pred1, aes(x=Year, y=crnp1_pred), lty=2, lwd=1.5) +
  geom_line(data=pred2, aes(x=Year, y=crnp2_pred), lty=3, lwd=1.5) +
  geom_line(data=pred3, aes(x=Year, y=crnp3_pred), lty=4, lwd=1.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/nonlinear_regression_files/figure-html/loess2-2.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;smoothing-splines&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Smoothing splines&lt;/h2&gt;
&lt;p&gt;In our next example, we will use the function &lt;em&gt;smooth.spline()&lt;/em&gt;. With this method, we can change the smoothing parameter and the methodology is based on crossed-validation to be able to define the parameter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Base method (by default)
cr_spline &amp;lt;- with(costa_rica, smooth.spline(x=Year, y=CO2_area))
cr_spline&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Call:
## smooth.spline(x = Year, y = CO2_area)
## 
## Smoothing Parameter  spar= 0.3976519  lambda= 6.497957e-05 (11 iterations)
## Equivalent Degrees of Freedom (Df): 9.578523
## Penalized Criterion (RSS): 2.323599e-08
## GCV: 3.740554e-09&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(cr_spline)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            Length Class             Mode   
## x          21     -none-            numeric
## y          21     -none-            numeric
## w          21     -none-            numeric
## yin        21     -none-            numeric
## tol         1     -none-            numeric
## data        3     -none-            list   
## no.weights  1     -none-            logical
## lev        21     -none-            numeric
## cv.crit     1     -none-            numeric
## pen.crit    1     -none-            numeric
## crit        1     -none-            numeric
## df          1     -none-            numeric
## spar        1     -none-            numeric
## ratio       1     -none-            numeric
## lambda      1     -none-            numeric
## iparms      5     -none-            numeric
## auxM        0     -none-            NULL   
## fit         5     smooth.spline.fit list   
## call        3     -none-            call&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;crsp_pred &amp;lt;- predict(cr_spline, data.frame(Year=seq(1,21,0.5)))
pred4 &amp;lt;- data.frame(Year=seq(1,21,0.5), crsp_pred)

#Compare the fit with the Loess fit
ej1 &amp;lt;- ggplot() 
ej1 +
  geom_point(data=costa_rica, aes(x=Year, y=CO2_area)) +
  geom_line(data=costa_rica, aes(x=Year, y=CO2_area), lty=1) +
  geom_line(data=pred1, aes(x=Year, y=crnp1_pred), lty=2, lwd=1.5) +
  geom_line(data=pred4, aes(x=Year, y=Year.2), lty=4, lwd=1.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/nonlinear_regression_files/figure-html/spline-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;change-smoothing-parameter&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Change smoothing parameter&lt;/h2&gt;
&lt;p&gt;We will now create a series of model runs where we change the smoothing parameter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cr25 &amp;lt;- with(costa_rica, smooth.spline(x=Year, y=CO2_area, spar=0.25))
pred25 &amp;lt;-  data.frame(Year=seq(1,21,0.5), pred=(predict(cr25, data.frame(Year=seq(1,21,0.5)))))

cr35 &amp;lt;- with(costa_rica, smooth.spline(x=Year, y=CO2_area, spar=0.35))
pred35 &amp;lt;-  data.frame(Year=seq(1,21,0.5), pred=(predict(cr35, data.frame(Year=seq(1,21,0.5)))))

cr45 &amp;lt;- with(costa_rica, smooth.spline(x=Year, y=CO2_area, spar=0.45))
pred45 &amp;lt;-  data.frame(Year=seq(1,21,0.5), pred=(predict(cr45, data.frame(Year=seq(1,21,0.5)))))

cr55 &amp;lt;- with(costa_rica, smooth.spline(x=Year, y=CO2_area, spar=0.55))
pred55 &amp;lt;-  data.frame(Year=seq(1,21,0.5), pred=(predict(cr55, data.frame(Year=seq(1,21,0.5)))))

cr65 &amp;lt;- with(costa_rica, smooth.spline(x=Year, y=CO2_area, spar=0.65))
pred65 &amp;lt;-  data.frame(Year=seq(1,21,0.5), pred=(predict(cr65, data.frame(Year=seq(1,21,0.5)))))

cr75 &amp;lt;- with(costa_rica, smooth.spline(x=Year, y=CO2_area, spar=0.75))
pred75 &amp;lt;-  data.frame(Year=seq(1,21,0.5), pred=(predict(cr75, data.frame(Year=seq(1,21,0.5)))))

cr85 &amp;lt;- with(costa_rica, smooth.spline(x=Year, y=CO2_area, spar=0.85))
pred85 &amp;lt;-  data.frame(Year=seq(1,21,0.5), pred=(predict(cr85, data.frame(Year=seq(1,21,0.5)))))

ej1 &amp;lt;- ggplot() 
ej1 +
  geom_point(data=costa_rica, aes(x=Year, y=CO2_area)) +
  geom_line(data=costa_rica, aes(x=Year, y=CO2_area), lty=1) +
  geom_line(data=pred25, aes(x=Year, y=pred.Year.1), lty=2, lwd=1.2) +
  geom_line(data=pred35, aes(x=Year, y=pred.Year.1), lty=3, lwd=1.2) +
  geom_line(data=pred45, aes(x=Year, y=pred.Year.1), lty=4, lwd=1.2) +
  geom_line(data=pred55, aes(x=Year, y=pred.Year.1), lty=5, lwd=1.2) +
  geom_line(data=pred65, aes(x=Year, y=pred.Year.1), lty=6, lwd=1.2) +
  geom_line(data=pred75, aes(x=Year, y=pred.Year.1), lty=2, lwd=1.3) +
  geom_line(data=pred85, aes(x=Year, y=pred.Year.1), lty=3, lwd=1.3) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/nonlinear_regression_files/figure-html/smoothers-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;last-word-for-now&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Last word for now&lt;/h2&gt;
&lt;p&gt;To close this discussion, it is natural to ask the following question, “What methods can we use to examine and control the smoothing parameter?”&lt;/p&gt;
&lt;p&gt;Within this list, there are several including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;trial and error,&lt;/li&gt;
&lt;li&gt;degree of smoothing compared with the data fidelity or reliability,&lt;/li&gt;
&lt;li&gt;minimize the mean square error,&lt;/li&gt;
&lt;li&gt;use cross-validation methods.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Nonparametric regression</title>
      <link>/post/nonparametric_regression/</link>
      <pubDate>Thu, 01 Aug 2019 21:08:05 -0500</pubDate>
      
      <guid>/post/nonparametric_regression/</guid>
      <description>


&lt;div id=&#34;background&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt;Nonlinear regression is an important modeling tool for looking at more compliated biological, physiological, etc., relationships. This introductory exercise describes some of the concepts that one should consider when analyzing nonlinear data. The process is iterative for modeling fitting, meaning that the parameters are estimated in a stepwise fashion. In Plant Pathology this is a useful tool for things like disease development over time. These models can be further extended to incorporated additional factors like treatments, years, among other things, to study the overall behavior and observed variability.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Note that for this example, we will keep the tools to those that are available in the base package

library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;This work originated in Costa Rica and focused on growth and development of onion in the northern areas of the Province of Cartago. Growth was measured using whole plant biomass. The goal was to understand how different varieties performed in this zone and future work would examine the impact of different management tactics and pests on improving overall productivity.&lt;/p&gt;
&lt;p&gt;The data strcuture for the orginal worked involved three cultivars but for the exercise we will only focus on one of those, which is called Alvara.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;dap = days after planting&lt;/li&gt;
&lt;li&gt;gdd = growing degree days based on threshold temperatures for onion&lt;/li&gt;
&lt;li&gt;root = root dry weight (grams)&lt;/li&gt;
&lt;li&gt;buld = bulb dry weight (grams)&lt;/li&gt;
&lt;li&gt;aerial = aerial biomass dry weight (grams)&lt;/li&gt;
&lt;li&gt;total = total dry weight considering the above measurements&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dap &amp;lt;- c(11, 18, 26, 33, 40, 47, 56, 61, 69, 82, 96, 111, 124)
gdd &amp;lt;- c(148, 233, 327, 410, 492, 575, 686, 746, 837, 993, 1158, 1335, 1484)
root &amp;lt;- c(0.04, 0.019, 0.113, 0.044, 0.045, 0.056, 0.08, 0.114, 0.109, 0.116, 0.098, 0.101, 0.066)
bulb &amp;lt;- c(0.137, 0.166, 0.289, 0.2, 0.292, 0.298, 0.474, 0.416, 1.236, 2.594, 6.265, 6.174, 
22.521)
aerial &amp;lt;- c(0.162, 0.191, 0.308, 0.243, 0.25, 0.343, 0.988, 0.962, 2.593, 3.379, 2.83, 5.054,
2.748)
total &amp;lt;- c(0.34, 0.376, 0.711, 0.487, 0.587, 0.698, 1.542, 1.492, 3.938, 6.089, 9.193, 11.329,
25.334)

alvara &amp;lt;- data.frame(dap, gdd, root, bulb, aerial, total)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;graphical-representation---preliminary&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Graphical representation - preliminary&lt;/h2&gt;
&lt;p&gt;Graphically, we will use some basic tools to look at the overall behavior.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## The predictive factor is growing degree days, assuming that best explains the overall growth and development

with(alvara, plot(x=gdd, y=root, type=&amp;quot;b&amp;quot;, lty=1, lwd=2, pch=19, col=&amp;quot;black&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/nonparametric_regression_files/figure-html/plots1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;with(alvara, plot(x=gdd, y=bulb, type=&amp;quot;b&amp;quot;, lty=1, lwd=2, pch=19, col=&amp;quot;black&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/nonparametric_regression_files/figure-html/plots1-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;with(alvara, plot(x=gdd, y=aerial, type=&amp;quot;b&amp;quot;, lty=1, lwd=2, pch=19, col=&amp;quot;black&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/nonparametric_regression_files/figure-html/plots1-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;with(alvara, plot(x=gdd, y=total, type=&amp;quot;b&amp;quot;, lty=1, lwd=2, pch=19, col=&amp;quot;black&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/nonparametric_regression_files/figure-html/plots1-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;modeling&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Modeling&lt;/h2&gt;
&lt;p&gt;Selecting a nonlinear model depends on many factors especially taking into account the biological relationship. In preliminary analyses with data of this type for onion, we saw two possible nonlinear models that best describe the relationships. In the first case the development was bell-shaped, showing increases until a specific point in the developmental process when dry weight was reduced. The second curve tupe was exponential and related to the ultimate growth phases just prior to harvest. Even though growth is not infinite, we still recognize that this model may explain well the relationship and is interpretable.&lt;/p&gt;
&lt;p&gt;Model 1.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ DW = \alpha * exp(-\beta * (gdd-\gamma)^2)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Where, DW is the dry weight (g), &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; is the measure of initial dry weight the start of evaluations (0 gdds), &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; is the growth rate, and &lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt; represents the inflexion point in the process. “gdd” are the accumulated growing degree days.&lt;/p&gt;
&lt;p&gt;Model 2.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ DW = X_0 * exp (K * gdd) \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where, DW is the dry weight (g), &lt;span class=&#34;math inline&#34;&gt;\(X_0\)&lt;/span&gt; is the condition where there has been no accumulation of heat units, and K is the growth rate as a function of the accumulated growing degree days (gdd).&lt;/p&gt;
&lt;p&gt;In both cases, it is important to take into account that the model will be adjusted based on the definition of the initial starting parameters. There are different methods to define initial starting parameters, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;using a grid search approach to find the best combination of all parameters in the model&lt;/li&gt;
&lt;li&gt;using preliminary analyses to define the parameters (can be based on similar data to your situation)&lt;/li&gt;
&lt;li&gt;functional estimate based on the model form and your knowledge about the system&lt;/li&gt;
&lt;li&gt;genetic algorithms, see for example, &lt;a href=&#34;https://en.wikipedia.org/wiki/Genetic_algorithm&#34; class=&#34;uri&#34;&gt;https://en.wikipedia.org/wiki/Genetic_algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;in R there are also for some of the models there are functions that will obtain initial starting parameters (see: &lt;a href=&#34;http://www.apsnet.org/edcenter/advanced/topics/EcologyAndEpidemiologyInR/DiseaseProgress/Pages/NonlinearRegression.aspx&#34; class=&#34;uri&#34;&gt;http://www.apsnet.org/edcenter/advanced/topics/EcologyAndEpidemiologyInR/DiseaseProgress/Pages/NonlinearRegression.aspx&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For the following examples, we will use the third method based on knowledge of the crop physiology and preliminary analyses.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model 1&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Variable = root dry weight
## nls = nonlinear least squares
## start=list() provides the input to define the initial starting values for the parameters

regnl1 &amp;lt;- nls(root ~ alpha * exp(-beta*(gdd-gamma)^2), 
              start=list(alpha = 0.15, beta = 0.0000002, gamma = 900), trace=TRUE, data=alvara)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 0.07027501 :  1.5e-01 2.0e-07 9.0e+02
## 0.008673095 :  1.007217e-01 7.854471e-07 1.308727e+03
## 0.007106798 :  9.761952e-02 1.203522e-06 1.002286e+03
## 0.006594237 :  1.069288e-01 1.562084e-06 1.021834e+03
## 0.006588507 :  1.079002e-01 1.618805e-06 1.016275e+03
## 0.006588451 :  1.079549e-01 1.621248e-06 1.016766e+03
## 0.00658845 :  1.079619e-01 1.621827e-06 1.016741e+03
## 0.00658845 :  1.079626e-01 1.621871e-06 1.016743e+03&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(regnl1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Formula: root ~ alpha * exp(-beta * (gdd - gamma)^2)
## 
## Parameters:
##        Estimate Std. Error t value Pr(&amp;gt;|t|)    
## alpha 1.080e-01  1.268e-02   8.516 6.78e-06 ***
## beta  1.622e-06  7.130e-07   2.275   0.0462 *  
## gamma 1.017e+03  9.913e+01  10.257 1.26e-06 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.02567 on 10 degrees of freedom
## 
## Number of iterations to convergence: 7 
## Achieved convergence tolerance: 2.89e-06&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Predictions

regnl_pred &amp;lt;- predict(regnl1, data.frame(gdd=seq(100,1500,25)))

## Database of predictions over a range of gdds

predictions &amp;lt;- data.frame(gdd=seq(100,1500,25), pred=regnl_pred)

## Graphically

ej1 &amp;lt;- ggplot() 
ej1 +
  geom_point(data=alvara, aes(x=gdd, y=root)) +
  geom_line(data=predictions, aes(x=gdd, y=pred), lty=1, lwd=1.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/nonparametric_regression_files/figure-html/model1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model 2&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Variable = total dry weight 

regnl2 &amp;lt;- nls(total ~ x0 * exp(k * gdd), start = list(x0=0.5, k=0.0002), trace=TRUE, data=alvara)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 838.571 :  5e-01 2e-04
## 745.1133 :  0.164848298 0.001679615
## 547.7136 :  0.066722470 0.002956091
## 231.1729 :  0.086874301 0.003337606
## 66.82676 :  0.124641432 0.003367594
## 17.75713 :  0.161921536 0.003372197
## 17.75511 :  0.16183068 0.00337153
## 17.75511 :  0.16184411 0.00337147&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(regnl2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Formula: total ~ x0 * exp(k * gdd)
## 
## Parameters:
##     Estimate Std. Error t value Pr(&amp;gt;|t|)    
## x0 0.1618441  0.0645079   2.509    0.029 *  
## k  0.0033715  0.0002832  11.905 1.26e-07 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 1.27 on 11 degrees of freedom
## 
## Number of iterations to convergence: 7 
## Achieved convergence tolerance: 5.642e-06&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Predictions

regn2_pred &amp;lt;- predict(regnl2, data.frame(gdd=seq(100,1500,25)))

## Database of predictions

predictions &amp;lt;- data.frame(gdd=seq(100,1500,25), pred=regn2_pred)

## Graphically

ej2 &amp;lt;- ggplot() 
ej2 +
  geom_point(data=alvara, aes(x=gdd, y=total)) +
  geom_line(data=predictions, aes(x=gdd, y=pred), lty=1, lwd=1.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/nonparametric_regression_files/figure-html/model2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exercises&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exercises&lt;/h2&gt;
&lt;p&gt;Perform the same set of the analyses for the following measurements and initial parameter conditions:&lt;/p&gt;
&lt;p&gt;Aerial dry weight, you can consider the following starting parameter values: start=list(alpha = 5, beta = 0.00002, gamma = 1100).&lt;/p&gt;
&lt;p&gt;Bulb dry weight, you can consider the following starting parameter values: start=list(x0 = 0.5, k = 0.0002).&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Mosquito Dose-Response</title>
      <link>/post/mosquito_dose_response/</link>
      <pubDate>Thu, 01 Aug 2019 21:08:04 -0500</pubDate>
      
      <guid>/post/mosquito_dose_response/</guid>
      <description>


&lt;div id=&#34;background&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt;This example was developed by Julie Baniszewski, a PhD student in the Department of Entomology at Penn State. Julie participated in our last workshop in Mexico under the INTAD-Tag Along program (International Agriculture and Development graduate program). This is a robust example of using dose-response methods in R based on generalized linear modeling concepts (including mixed model).&lt;/p&gt;
&lt;p&gt;Data set:
Mosquito toxicity was tested with 4 instars and monitored until pupation. The experimental design was 3 blocks with 4 replicates each to test mosquito toxicity.&lt;/p&gt;
&lt;p&gt;The aim is to look at ultimate %pupation and LC50, LC90 for 24, 48 hrs.&lt;/p&gt;
&lt;p&gt;What is in the database?
* Concentration = weight:volume concentration of chemical
* Instar = 1-4 stages of mosquito larvae introduced to chemical treatment
* Block = Growth Chamber
* Rep = 1-4 replicates within each block
* Total = total number of initial larvae
* Pupae = total number of larvae that reached pupation
* %Pupated = % larvae that pupated and ultimately survived the treatment
* Day0 = total number of initial larvae
* Day1p = proportion of larvae mortality on Day 1 post chemical exposure
* Day2p = proportion of larvae mortality on Day 2 post chemical exposure&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;load-packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Load packages&lt;/h2&gt;
&lt;p&gt;Here, we will use the readxl package to work with Excel-oriented files. Like the nonparametric regression example, we have defined a local repository for the file and this can be changed for individual use. We have several other different packages specific to work with dose-response curves and model fitting.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(readxl)
library(drc)
library(car)
library(cowplot)
library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Importing data set:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;DR &amp;lt;- read_excel(&amp;quot;DR_Data_Sheet.xlsx&amp;quot;)
str(DR)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Classes &amp;#39;tbl_df&amp;#39;, &amp;#39;tbl&amp;#39; and &amp;#39;data.frame&amp;#39;:    288 obs. of  22 variables:
##  $ Concentration: num  0 0 0 0 1 1 1 1 0.75 0.75 ...
##  $ Instar       : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ Block        : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ Rep          : num  1 2 3 4 1 2 3 4 1 2 ...
##  $ Total        : num  10 11 10 10 10 10 10 10 10 10 ...
##  $ Pupae        : num  9 11 8 9 0 0 0 0 0 0 ...
##  $ %Pupated     : num  0.9 1 0.8 0.9 0 0 0 0 0 0 ...
##  $ Day0         : num  10 11 10 10 10 10 10 10 10 10 ...
##  $ Day1p        : num  0.1 0 0.1 0.1 1 0.8 0.9 0.9 0.8 0.7 ...
##  $ Day2p        : num  0.1 0 0.1 0.1 1 1 1 1 1 0.9 ...
##  $ Day3p        : num  0.1 0 0.1 0.1 1 1 1 1 1 1 ...
##  $ Day4p        : num  0.1 0 0.1 0.1 1 1 1 1 1 1 ...
##  $ Day5p        : num  0.1 0 0.1 0.1 1 1 1 1 1 1 ...
##  $ Day6p        : num  0.1 0 0.1 0.1 1 1 1 1 1 1 ...
##  $ Day7p        : num  0.1 0 0.1 0.1 1 1 1 1 1 1 ...
##  $ Day8p        : num  0.1 0 0.1 0.1 1 1 1 1 1 1 ...
##  $ Day9p        : num  0.1 0 0.1 0.1 1 1 1 1 1 1 ...
##  $ Day10p       : num  0.1 0 0.1 0.1 1 1 1 1 1 1 ...
##  $ Day11p       : num  0.1 0 0.1 0.1 1 1 1 1 1 1 ...
##  $ Day12p       : num  0.1 0 0.1 0.1 1 1 1 1 1 1 ...
##  $ Day13p       : num  0.1 0 0.2 0.1 1 1 1 1 1 1 ...
##  $ Day14p       : num  0.1 0 0.2 0.1 1 1 1 1 1 1 ...&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(DR)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Concentration        Instar         Block        Rep           Total           Pupae           %Pupated          Day0           Day1p            Day2p            Day3p            Day4p             Day5p            Day6p            Day7p            Day8p            Day9p            Day10p           Day11p           Day12p           Day13p           Day14p      
##  Min.   :0.0000   Min.   :1.00   Min.   :1   Min.   :1.00   Min.   :10.00   Min.   : 0.000   Min.   :0.000   Min.   :10.00   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.00000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  
##  1st Qu.:0.1000   1st Qu.:1.75   1st Qu.:1   1st Qu.:1.75   1st Qu.:10.00   1st Qu.: 0.000   1st Qu.:0.000   1st Qu.:10.00   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.08333   1st Qu.:0.1000   1st Qu.:0.1000   1st Qu.:0.1000   1st Qu.:0.1000   1st Qu.:0.1000   1st Qu.:0.1000   1st Qu.:0.1404   1st Qu.:0.1404   1st Qu.:0.4000   1st Qu.:0.4000  
##  Median :0.3750   Median :2.50   Median :2   Median :2.50   Median :10.00   Median : 0.000   Median :0.000   Median :10.00   Median :0.3000   Median :0.6500   Median :0.7500   Median :0.80000   Median :0.8500   Median :0.9000   Median :0.9000   Median :1.0000   Median :1.0000   Median :1.0000   Median :1.0000   Median :1.0000   Median :1.0000   Median :1.0000  
##  Mean   :0.4333   Mean   :2.50   Mean   :2   Mean   :2.50   Mean   :10.17   Mean   : 3.615   Mean   :0.346   Mean   :10.17   Mean   :0.3924   Mean   :0.5186   Mean   :0.5499   Mean   :0.56945   Mean   :0.5846   Mean   :0.6026   Mean   :0.6179   Mean   :0.6258   Mean   :0.6367   Mean   :0.6425   Mean   :0.6745   Mean   :0.6778   Mean   :0.7434   Mean   :0.7454  
##  3rd Qu.:0.7500   3rd Qu.:3.25   3rd Qu.:3   3rd Qu.:3.25   3rd Qu.:10.00   3rd Qu.: 9.000   3rd Qu.:0.900   3rd Qu.:10.00   3rd Qu.:0.8000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.00000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  
##  Max.   :1.0000   Max.   :4.00   Max.   :3   Max.   :4.00   Max.   :14.00   Max.   :14.000   Max.   :1.000   Max.   :14.00   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.00000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;preliminary-examination-of-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Preliminary examination of data&lt;/h2&gt;
&lt;p&gt;Start by looking at data (ultimate survival): dependent variable ‘%pupation’&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;op &amp;lt;- par(mfrow = c(1, 2), mar=c(3.2,3.2,2,.5), mgp=c(2,.7,0)) #make two plots in two columns 
plot(DR$`%Pupated` ~ DR$Concentration, data = DR, main=&amp;quot;Original Dose Scale&amp;quot;)
plot(DR$`%Pupated` ~ logit(DR$Concentration+0.01), data = DR, main=&amp;quot;Logarithmic Dose Scale&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/Look%20at%20data%20response%20plots%20without%20and%20with%20logit%20scale-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Look at control data&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#if mortality is &amp;gt;&amp;gt; 5%, may need Abbot&amp;#39;s Formula for correction (Correction%= (1-treatmetn/control)*100)

aggregate(DR[,7], list(DR$Concentration), mean)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Group.1  %Pupated
## 1    0.00 0.9429293
## 2    0.10 0.9127889
## 3    0.25 0.2204545
## 4    0.50 0.0000000
## 5    0.75 0.0000000
## 6    1.00 0.0000000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Control is ~5% motality, is okay&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;initial-models-dose-response-and-linear&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Initial models: dose-response and linear&lt;/h2&gt;
&lt;p&gt;Option 1: use Dose Response Model&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;DR1&amp;lt;-drm(DR$`%Pupated` ~ log1p(DR$Concentration), DR$Instar, data = DR, fct=LL.2(names=c(&amp;quot;Slope&amp;quot;, &amp;quot;LD50&amp;quot;)), type=(&amp;quot;binomial&amp;quot;), na.action=na.omit)
summary(DR1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Model fitted: Log-logistic (ED50 as parameter) with lower limit at 0 and upper limit at 1 (2 parms)
## 
## Parameter estimates:
## 
##         Estimate Std. Error t-value   p-value    
## Slope:1 5.281684   1.480907  3.5665 0.0003618 ***
## Slope:2 4.639606   1.259559  3.6835 0.0002300 ***
## Slope:3 5.063119   1.466544  3.4524 0.0005556 ***
## Slope:4 4.753037   1.414136  3.3611 0.0007764 ***
## LD50:1  0.148070   0.019217  7.7050 1.309e-14 ***
## LD50:2  0.147669   0.019483  7.5795 3.466e-14 ***
## LD50:3  0.167355   0.021347  7.8398 4.477e-15 ***
## LD50:4  0.193382   0.023076  8.3800 &amp;lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#look at residuals
op &amp;lt;- par(mfrow = c(1, 2), mar=c(3.2,3.2,2,.5), mgp=c(2,.7,0)) #put two graphs together
plot(residuals(DR1) ~ fitted(DR1), main=&amp;quot;Residuals vs Fitted&amp;quot;)
abline(h=0) #should look random
qqnorm(residuals(DR1))
qqline(residuals(DR1)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/DR%20model-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#shows slope of pupation, LD50 is significantly different than 0 for each instar
par(mfrow = c(1, 1), mar=c(3.2,3.2,.5,.5), mgp=c(2,.7,0))
plot(DR1, broken=TRUE, xlim=c(0,2), bty=&amp;quot;l&amp;quot;, xlab=&amp;quot;Concentration&amp;quot;, ylab=&amp;quot;Survival to Pupation&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/DR%20model-2.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modelFit(DR1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Goodness-of-fit test
## 
##              Df Chisq value p value
##                                    
## DRC model   232      16.065       1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;EDcomp(DR1,c(50,50), reverse=TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Estimated ratios of effect doses
## 
##            Estimate Std. Error   t-value   p-value
## 2/1:50/50  0.997289   0.184569 -0.014688  0.988281
## 3/1:50/50  1.130243   0.205675  0.633247  0.526572
## 4/1:50/50  1.306015   0.230260  1.328998  0.183849
## 3/2:50/50  1.133315   0.207978  0.641007  0.521518
## 4/2:50/50  1.309565   0.232965  1.328803  0.183913
## 4/3:50/50  1.155517   0.201836  0.770511  0.440997&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Instar has little effect on pupation, instars 1 and 2 very similar, 3 and 4 increasing survival. Overall, model doesn&amp;#39;t fit well.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Option 2: look at linear model&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pairs(DR$`%Pupated` ~ (DR$Block) + (DR$Rep) + DR$Concentration + DR$Instar)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/Linear%20Model-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Concentration has trend with % pupated; block/reps random, no pattern as expected. Instar appears to have little effect
op &amp;lt;- par(mfrow = c(1, 1), mar=c(3.2,3.2,0,.5), mgp=c(2,.7,0))
plot(DR$`%Pupated` ~ DR$Concentration, data = DR, bty=&amp;quot;l&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/Linear%20Model-2.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pupation.lm1 &amp;lt;- lm(DR$`%Pupated` ~ (Block) + (Rep) + Concentration + Instar + Concentration:Instar, data = DR)
summary(pupation.lm1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = DR$`%Pupated` ~ (Block) + (Rep) + Concentration + 
##     Instar + Concentration:Instar, data = DR)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.55033 -0.25374 -0.01523  0.21556  0.38197 
## 
## Coefficients:
##                       Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)           0.667166   0.073091   9.128   &amp;lt;2e-16 ***
## Block                 0.003084   0.017585   0.175   0.8609    
## Rep                   0.003364   0.012842   0.262   0.7936    
## Concentration        -0.895659   0.098928  -9.054   &amp;lt;2e-16 ***
## Instar                0.037893   0.020247   1.871   0.0623 .  
## Concentration:Instar -0.039072   0.036123  -1.082   0.2803    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.2437 on 282 degrees of freedom
## Multiple R-squared:  0.6835, Adjusted R-squared:  0.6778 
## F-statistic: 121.8 on 5 and 282 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(pupation.lm1, bty=&amp;quot;l&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/Linear%20Model-3.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/Linear%20Model-4.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/Linear%20Model-5.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/Linear%20Model-6.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#look at residuals
op &amp;lt;- par(mfrow = c(1, 2), mar=c(3.2,3.2,2,.5), mgp=c(2,.7,0)) #put two graphs together
plot(residuals(pupation.lm1) ~ fitted(pupation.lm1), main=&amp;quot;Residuals vs Fitted&amp;quot;)
abline(h=0) #should look random
qqnorm(residuals(pupation.lm1))
qqline(residuals(pupation.lm1)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/Linear%20Model-7.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#not quite normal on QQ plot, residuals not random -&amp;gt; use logit or beta distribution&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#logit binomial dist
pupation.lm2 &amp;lt;- glm((DR$`%Pupated`)~ (DR$Block) + (DR$Rep) + (DR$Concentration) + (DR$Instar) + (DR$Concentration:DR$Instar), family = binomial(link = &amp;quot;logit&amp;quot;))
plot(pupation.lm2, bty=&amp;quot;l&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/Linear%20Model%20with%20logit%20bionomial%20distribution%20because%20violation%20of%20normality%20assumption-1.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/Linear%20Model%20with%20logit%20bionomial%20distribution%20because%20violation%20of%20normality%20assumption-2.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/Linear%20Model%20with%20logit%20bionomial%20distribution%20because%20violation%20of%20normality%20assumption-3.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/Linear%20Model%20with%20logit%20bionomial%20distribution%20because%20violation%20of%20normality%20assumption-4.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#look at residuals
plot(residuals(pupation.lm2) ~ fitted(pupation.lm2), main=&amp;quot;Residuals vs Fitted&amp;quot;)
abline(h=0) #should look random&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/Linear%20Model%20with%20logit%20bionomial%20distribution%20because%20violation%20of%20normality%20assumption-5.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;qqnorm(residuals(pupation.lm1))
qqline(residuals(pupation.lm1)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/Linear%20Model%20with%20logit%20bionomial%20distribution%20because%20violation%20of%20normality%20assumption-6.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#residuals random, more normal on qqplot
summary(pupation.lm2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## glm(formula = (DR$`%Pupated`) ~ (DR$Block) + (DR$Rep) + (DR$Concentration) + 
##     (DR$Instar) + (DR$Concentration:DR$Instar), family = binomial(link = &amp;quot;logit&amp;quot;))
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.25219  -0.06925  -0.00233   0.12168   0.72655  
## 
## Coefficients:
##                             Estimate Std. Error z value Pr(&amp;gt;|z|)   
## (Intercept)                  3.03900    1.56721   1.939  0.05249 . 
## DR$Block                     0.05845    0.31427   0.186  0.85247   
## DR$Rep                       0.06374    0.22962   0.278  0.78132   
## DR$Concentration           -22.86314    7.28283  -3.139  0.00169 **
## DR$Instar                    0.22619    0.52014   0.435  0.66366   
## DR$Concentration:DR$Instar   0.96115    2.62361   0.366  0.71411   
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 295.246  on 287  degrees of freedom
## Residual deviance:  24.113  on 282  degrees of freedom
## AIC: 58.259
## 
## Number of Fisher Scoring iterations: 8&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#compare linear model with non linear, linear &amp;gt; DR2 due to much lower AIC
AIC(DR1, pupation.lm2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              df       AIC
## DR1           8 245.08353
## pupation.lm2  6  58.25937&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;log-logistic-and-weibull-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Log-logistic and Weibull models&lt;/h2&gt;
&lt;p&gt;Other tools related to dose-response models&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#compare log-logistic and Weibull models (pooling instar because non-significant)
DR0 &amp;lt;- drm(DR$`%Pupated` ~ DR$Concentration, data = DR, fct = LL.4())
DR1 &amp;lt;- drm(DR$`%Pupated` ~ DR$Concentration, data = DR, fct = W1.4())
DR2 &amp;lt;- drm(DR$`%Pupated` ~ DR$Concentration, data = DR, fct = W2.4())

par(mfrow=c(1,1), mar=c(3.2,3.2,.5,.5), mgp=c(2,.7,0))
plot(DR0, broken=TRUE, xlab=&amp;quot;Conc&amp;quot;, ylab=&amp;quot;% Pupation&amp;quot;, lwd=2, cex=1.2, cex.axis=1.2, cex.lab=1.2, bty=&amp;quot;l&amp;quot;)
plot(DR1, add=TRUE, broken=TRUE, lty=2, lwd=2) #Weibull-1
plot(DR2, add=TRUE, broken=TRUE, lty=3, lwd=2) #Weibull-2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/DR%20other%20tools-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Effective dose
ED(DR1,50,interval=&amp;quot;delta&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Estimated effective doses
## 
##         Estimate Std. Error     Lower     Upper
## e:1:50 0.2092415  0.0066148 0.1962212 0.2222618&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ED(DR1,90,interval=&amp;quot;delta&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Estimated effective doses
## 
##         Estimate Std. Error     Lower     Upper
## e:1:90 0.2795042  0.0057066 0.2682715 0.2907369&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ED(DR1,95,interval=&amp;quot;delta&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Estimated effective doses
## 
##         Estimate Std. Error     Lower     Upper
## e:1:95 0.2978175  0.0088051 0.2804860 0.3151490&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;edLL&amp;lt;-data.frame(ED(DR0,c(10,50,90),interval=&amp;quot;delta&amp;quot;, display=FALSE),ll=&amp;quot;Log-logistic&amp;quot;)            
edW1&amp;lt;-data.frame(ED(DR1,c(10,50,90),interval=&amp;quot;delta&amp;quot;, display=FALSE),ll=&amp;quot;Weibull 1&amp;quot;)
edW2&amp;lt;-data.frame(ED(DR2,c(10,50,90),interval=&amp;quot;delta&amp;quot;, display=FALSE),ll=&amp;quot;Weibull 2&amp;quot;)
CombED&amp;lt;-rbind(edLL,edW1,edW2)

p1 &amp;lt;- ggplot(data=CombED[c(1,4,7),], aes(x=ll, y=Estimate))+ geom_bar(stat=&amp;quot;identity&amp;quot;, fill=&amp;quot;lightgreen&amp;quot;, colour=&amp;quot;black&amp;quot;)+
  geom_errorbar(aes(ymin=Lower, ymax=Upper), width=0.1) + ylab(&amp;quot;ED10&amp;quot;)+  xlab(&amp;quot;&amp;quot;)
p2 &amp;lt;- ggplot(data=CombED[c(2,5,8),], aes(x=ll, y=Estimate))+ geom_bar(stat=&amp;quot;identity&amp;quot;, fill=&amp;quot;lightgreen&amp;quot;, colour=&amp;quot;black&amp;quot;)+
  geom_errorbar(aes(ymin=Lower, ymax=Upper), width=0.1) + ylab(&amp;quot;ED50&amp;quot;)+ xlab(&amp;quot;&amp;quot;)
p3 &amp;lt;- ggplot(data=CombED[c(3,6,9),], aes(x=ll, y=Estimate))+ geom_bar(stat=&amp;quot;identity&amp;quot;, fill=&amp;quot;lightgreen&amp;quot;, colour=&amp;quot;black&amp;quot;)+
  geom_errorbar(aes(ymin=Lower, ymax=Upper), width=0.1) + ylab(&amp;quot;ED90&amp;quot;)+  xlab(&amp;quot;Sigmoid four parameter models&amp;quot;)
plot_grid(p1,p2,p3, ncol=1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/DR%20other%20tools-2.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#look at different tests, either Log-logistic or Weibull 1 most appropriate

comped(CombED[c(1,4),1],CombED[c(1,4),2],log=F,operator = &amp;quot;-&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Estimated difference of effective doses
## 
##        Estimate Std. Error      Lower Upper
## [1,] -0.0034982  0.0186068 -0.0399669 0.033&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mortality-example-24-hr&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Mortality Example 24 hr&lt;/h2&gt;
&lt;p&gt;Look at Day 1 (24hr Mortality)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(DR)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Concentration        Instar         Block        Rep           Total           Pupae           %Pupated          Day0           Day1p            Day2p            Day3p            Day4p             Day5p            Day6p            Day7p            Day8p            Day9p            Day10p           Day11p           Day12p           Day13p           Day14p      
##  Min.   :0.0000   Min.   :1.00   Min.   :1   Min.   :1.00   Min.   :10.00   Min.   : 0.000   Min.   :0.000   Min.   :10.00   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.00000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  
##  1st Qu.:0.1000   1st Qu.:1.75   1st Qu.:1   1st Qu.:1.75   1st Qu.:10.00   1st Qu.: 0.000   1st Qu.:0.000   1st Qu.:10.00   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.08333   1st Qu.:0.1000   1st Qu.:0.1000   1st Qu.:0.1000   1st Qu.:0.1000   1st Qu.:0.1000   1st Qu.:0.1000   1st Qu.:0.1404   1st Qu.:0.1404   1st Qu.:0.4000   1st Qu.:0.4000  
##  Median :0.3750   Median :2.50   Median :2   Median :2.50   Median :10.00   Median : 0.000   Median :0.000   Median :10.00   Median :0.3000   Median :0.6500   Median :0.7500   Median :0.80000   Median :0.8500   Median :0.9000   Median :0.9000   Median :1.0000   Median :1.0000   Median :1.0000   Median :1.0000   Median :1.0000   Median :1.0000   Median :1.0000  
##  Mean   :0.4333   Mean   :2.50   Mean   :2   Mean   :2.50   Mean   :10.17   Mean   : 3.615   Mean   :0.346   Mean   :10.17   Mean   :0.3924   Mean   :0.5186   Mean   :0.5499   Mean   :0.56945   Mean   :0.5846   Mean   :0.6026   Mean   :0.6179   Mean   :0.6258   Mean   :0.6367   Mean   :0.6425   Mean   :0.6745   Mean   :0.6778   Mean   :0.7434   Mean   :0.7454  
##  3rd Qu.:0.7500   3rd Qu.:3.25   3rd Qu.:3   3rd Qu.:3.25   3rd Qu.:10.00   3rd Qu.: 9.000   3rd Qu.:0.900   3rd Qu.:10.00   3rd Qu.:0.8000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.00000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  
##  Max.   :1.0000   Max.   :4.00   Max.   :3   Max.   :4.00   Max.   :14.00   Max.   :14.000   Max.   :1.000   Max.   :14.00   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.00000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;op &amp;lt;- par(mfrow = c(1, 2), mar=c(3.2,3.2,2,.5), mgp=c(2,.7,0)) 
plot(DR$Day1p~ DR$Concentration, data = DR, main=&amp;quot;Original Dose Scale&amp;quot;)
plot(DR$Day1p ~ logit(DR$Concentration+0.01), data = DR, main=&amp;quot;Logarithmic Dose Scale&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/DR%20Day%201%20mortality%20Data-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Look at control data, make sure mortality is &amp;lt; ~ 5%
aggregate(DR[,9], list(DR$Concentration), mean)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Group.1      Day1p
## 1    0.00 0.02083333
## 2    0.10 0.01666667
## 3    0.25 0.09166667
## 4    0.50 0.55416667
## 5    0.75 0.78541667
## 6    1.00 0.88541667&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Option 1:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#option 1: use DR
Day1DR&amp;lt;-drm(DR$Day1p ~ DR$Concentration, DR$Instar, data = DR, fct=LL.2(names=c(&amp;quot;Slope&amp;quot;, &amp;quot;LD50&amp;quot;)), type=(&amp;quot;binomial&amp;quot;), na.action=na.omit)
summary(Day1DR)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Model fitted: Log-logistic (ED50 as parameter) with lower limit at 0 and upper limit at 1 (2 parms)
## 
## Parameter estimates:
## 
##          Estimate Std. Error t-value   p-value    
## Slope:1 -2.384882   0.608538 -3.9190 8.890e-05 ***
## Slope:2 -3.182438   0.801062 -3.9728 7.104e-05 ***
## Slope:3 -3.345483   0.905529 -3.6945 0.0002203 ***
## Slope:4 -3.460856   0.880632 -3.9300 8.496e-05 ***
## LD50:1   0.457671   0.066102  6.9237 4.400e-12 ***
## LD50:2   0.461353   0.056611  8.1495 4.047e-16 ***
## LD50:3   0.561857   0.062752  8.9536 &amp;lt; 2.2e-16 ***
## LD50:4   0.470069   0.054920  8.5592 &amp;lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#shows slope, LD50 is significantly different than 0 for each instar
par(mfrow = c(1, 1), mar=c(3.2,3.2,.5,.5), mgp=c(2,.7,0))
plot(Day1DR, broken=TRUE, xlim=c(0,2), bty=&amp;quot;l&amp;quot;, xlab=&amp;quot;Concentration&amp;quot;, ylab=&amp;quot;Mortality&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/DR%20Mortality-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;EDcomp(Day1DR,c(50,50), reverse=TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Estimated ratios of effect doses
## 
##            Estimate Std. Error   t-value   p-value
## 2/1:50/50  1.008045   0.191044  0.042111  0.966410
## 3/1:50/50  1.227643   0.224140  1.015629  0.309806
## 4/1:50/50  1.027089   0.190803  0.141975  0.887100
## 3/2:50/50  1.217845   0.202070  1.078068  0.281003
## 4/2:50/50  1.018892   0.172632  0.109437  0.912856
## 4/3:50/50  0.836635   0.135225 -1.208096  0.227010&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Instar has little effect on mortality, instars 1 and 2 similar, 3 and 4 less responsive. Overall, model doesn&amp;#39;t fit well.

#look at residuals
op &amp;lt;- par(mfrow = c(1, 2), mar=c(3.2,3.2,2,.5), mgp=c(2,.7,0)) 
plot(residuals(Day1DR) ~ fitted(Day1DR), main=&amp;quot;Residuals vs Fitted&amp;quot;)
qqnorm(residuals(Day1DR))
qqline(residuals(Day1DR)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/DR%20Mortality-2.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#data not normally distributed

op &amp;lt;- par(mfrow = c(1, 2), mar=c(3.2,3.2,.5,.5), mgp=c(2,.7,0))
plot(Day1DR, broken=TRUE, bty=&amp;quot;l&amp;quot;, xlab=&amp;quot;Conc&amp;quot;, ylab=&amp;quot;Mortality&amp;quot;)
plot(Day1DR, broken=TRUE, bty=&amp;quot;l&amp;quot;, xlab=&amp;quot;Concentration&amp;quot;, ylab=&amp;quot;Mortality&amp;quot;,type=&amp;quot;all&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/DR%20Mortality-3.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modelFit(Day1DR)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Goodness-of-fit test
## 
##              Df Chisq value p value
##                                    
## DRC model   232      57.143       1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#model doesn&amp;#39;t fit very well, instar doesnt have much effect on DR&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Option 2:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Option 2: look at linear model
pairs(DR$Day1p ~ (DR$Block) + (DR$Rep) + DR$Concentration + DR$Instar)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/LM%20mortality-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;op &amp;lt;- par(mfrow = c(1, 1), mar=c(3.2,3.2,0,.5), mgp=c(2,.7,0))
plot(DR$Day1p ~ DR$Concentration, data = DR, bty=&amp;quot;l&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/LM%20mortality-2.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;day1.lm &amp;lt;- lm(DR$Day1p ~ (Block) + (Rep) + Concentration + Instar + Concentration:Instar, data = DR)
summary(day1.lm)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = DR$Day1p ~ (Block) + (Rep) + Concentration + Instar + 
##     Concentration:Instar, data = DR)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.56986 -0.08445  0.00331  0.07096  0.53949 
## 
## Coefficients:
##                       Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)           0.021339   0.048693   0.438   0.6615    
## Block                 0.005729   0.011715   0.489   0.6252    
## Rep                  -0.006667   0.008556  -0.779   0.4365    
## Concentration         0.913095   0.065906  13.855   &amp;lt;2e-16 ***
## Instar               -0.022310   0.013489  -1.654   0.0993 .  
## Concentration:Instar  0.033535   0.024065   1.393   0.1646    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.1623 on 282 degrees of freedom
## Multiple R-squared:   0.83,  Adjusted R-squared:  0.827 
## F-statistic: 275.3 on 5 and 282 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(day1.lm, which=1, bty=&amp;quot;l&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/LM%20mortality-3.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#look at residuals
plot(residuals(day1.lm) ~ fitted(day1.lm), main=&amp;quot;Residuals vs Fitted&amp;quot;)
abline(h=0) #should look random&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/LM%20mortality-4.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;qqnorm(residuals(day1.lm))
qqline(residuals(day1.lm)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/LM%20mortality-5.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# fit with binomial dist
day1.lm2 &amp;lt;- glm((DR$Day1p)~ (DR$Block) + (DR$Rep) + (DR$Concentration) + (DR$Instar) + (DR$Concentration:DR$Instar), family = binomial(link = &amp;quot;logit&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in eval(family$initialize): non-integer #successes in a binomial glm!&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(day1.lm2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## glm(formula = (DR$Day1p) ~ (DR$Block) + (DR$Rep) + (DR$Concentration) + 
##     (DR$Instar) + (DR$Concentration:DR$Instar), family = binomial(link = &amp;quot;logit&amp;quot;))
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.6080  -0.3367  -0.1780   0.2638   1.3359  
## 
## Coefficients:
##                            Estimate Std. Error z value Pr(&amp;gt;|z|)   
## (Intercept)                -2.51902    1.05333  -2.391  0.01678 * 
## DR$Block                    0.05248    0.21850   0.240  0.81017   
## DR$Rep                     -0.06107    0.15964  -0.383  0.70205   
## DR$Concentration            4.84531    1.53331   3.160  0.00158 **
## DR$Instar                  -0.39914    0.35381  -1.128  0.25926   
## DR$Concentration:DR$Instar  0.64192    0.61519   1.043  0.29674   
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 234.383  on 287  degrees of freedom
## Residual deviance:  53.056  on 282  degrees of freedom
## AIC: 153.42
## 
## Number of Fisher Scoring iterations: 6&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(day1.lm2, which=1, bty=&amp;quot;l&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/LM%20mortality-6.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(residuals(day1.lm2) ~ fitted(day1.lm2), main=&amp;quot;Residuals vs Fitted&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/LM%20mortality-7.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;qqnorm(residuals(day1.lm2))
qqline(residuals(day1.lm2)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/LM%20mortality-8.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#binomial logit fits better&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#compare linear model with DR, linear &amp;gt; DR due to lower AIC
AIC(Day1DR, day1.lm2, k=2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          df      AIC
## Day1DR    8 256.6130
## day1.lm2  6 153.4244&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(day1.lm2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## glm(formula = (DR$Day1p) ~ (DR$Block) + (DR$Rep) + (DR$Concentration) + 
##     (DR$Instar) + (DR$Concentration:DR$Instar), family = binomial(link = &amp;quot;logit&amp;quot;))
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.6080  -0.3367  -0.1780   0.2638   1.3359  
## 
## Coefficients:
##                            Estimate Std. Error z value Pr(&amp;gt;|z|)   
## (Intercept)                -2.51902    1.05333  -2.391  0.01678 * 
## DR$Block                    0.05248    0.21850   0.240  0.81017   
## DR$Rep                     -0.06107    0.15964  -0.383  0.70205   
## DR$Concentration            4.84531    1.53331   3.160  0.00158 **
## DR$Instar                  -0.39914    0.35381  -1.128  0.25926   
## DR$Concentration:DR$Instar  0.64192    0.61519   1.043  0.29674   
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 234.383  on 287  degrees of freedom
## Residual deviance:  53.056  on 282  degrees of freedom
## AIC: 153.42
## 
## Number of Fisher Scoring iterations: 6&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Other Tools:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Using drm package to determine effective dose.
#compare log-logistic and Weibull models (pooling instar because non-significant)
Day1DR &amp;lt;- drm(DR$Day1p ~ DR$Concentration, data = DR, fct = LL.4())
Day1DR2 &amp;lt;- drm(DR$Day1p ~ DR$Concentration, data = DR, fct = W1.4())
Day1DR3 &amp;lt;- drm(DR$Day1p ~ DR$Concentration, data = DR, fct = W2.4())

par(mfrow=c(1,1), mar=c(3.2,3.2,.5,.5), mgp=c(2,.7,0))
plot(Day1DR, broken=TRUE, xlab=&amp;quot;Conc&amp;quot;, ylab=&amp;quot;% Pupation&amp;quot;, lwd=2, cex=1.2, cex.axis=1.2, cex.lab=1.2, bty=&amp;quot;l&amp;quot;)
plot(Day1DR2, add=TRUE, broken=TRUE, lty=2, lwd=2) #Weibull-1
plot(Day1DR3, add=TRUE, broken=TRUE, lty=3, lwd=2) #Weibull-2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/Day%201%20Mortality%20Wiebull-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Effective dose using log-logistic model
ED(Day1DR,50,interval=&amp;quot;delta&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Estimated effective doses
## 
##        Estimate Std. Error   Lower   Upper
## e:1:50  0.45532    0.01532 0.42517 0.48548&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ED(Day1DR,90,interval=&amp;quot;delta&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Estimated effective doses
## 
##        Estimate Std. Error    Lower    Upper
## e:1:90 0.809377   0.069525 0.672527 0.946227&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ED(Day1DR,95,interval=&amp;quot;delta&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Estimated effective doses
## 
##        Estimate Std. Error   Lower   Upper
## e:1:95  0.98426    0.10692 0.77380 1.19473&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;edLL&amp;lt;-data.frame(ED(Day1DR,c(10,50,90),interval=&amp;quot;delta&amp;quot;, display=FALSE),ll=&amp;quot;Log-logistic&amp;quot;)            
edW1&amp;lt;-data.frame(ED(Day1DR2,c(10,50,90),interval=&amp;quot;delta&amp;quot;, display=FALSE),ll=&amp;quot;Weibull 1&amp;quot;)
edW2&amp;lt;-data.frame(ED(Day1DR3,c(10,50,90),interval=&amp;quot;delta&amp;quot;, display=FALSE),ll=&amp;quot;Weibull 2&amp;quot;)
CombED&amp;lt;-rbind(edLL,edW1,edW2)

p1 &amp;lt;- ggplot(data=CombED[c(1,4,7),], aes(x=ll, y=Estimate))+ geom_bar(stat=&amp;quot;identity&amp;quot;, fill=&amp;quot;lightgreen&amp;quot;, colour=&amp;quot;black&amp;quot;)+
  geom_errorbar(aes(ymin=Lower, ymax=Upper), width=0.1) + ylab(&amp;quot;ED10&amp;quot;)+  xlab(&amp;quot;&amp;quot;)
p2 &amp;lt;- ggplot(data=CombED[c(2,5,8),], aes(x=ll, y=Estimate))+ geom_bar(stat=&amp;quot;identity&amp;quot;, fill=&amp;quot;lightgreen&amp;quot;, colour=&amp;quot;black&amp;quot;)+
  geom_errorbar(aes(ymin=Lower, ymax=Upper), width=0.1) + ylab(&amp;quot;ED50&amp;quot;)+ xlab(&amp;quot;&amp;quot;)
p3 &amp;lt;- ggplot(data=CombED[c(3,6,9),], aes(x=ll, y=Estimate))+ geom_bar(stat=&amp;quot;identity&amp;quot;, fill=&amp;quot;lightgreen&amp;quot;, colour=&amp;quot;black&amp;quot;)+
  geom_errorbar(aes(ymin=Lower, ymax=Upper), width=0.1) + ylab(&amp;quot;ED90&amp;quot;)+  xlab(&amp;quot;Sigmoid four parameter models&amp;quot;)
plot_grid(p1,p2,p3, ncol=1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/Day%201%20Mortality%20Wiebull-2.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mortality-example-48-hr&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Mortality Example 48 hr&lt;/h2&gt;
&lt;p&gt;Look at Day 2 (48hr) Mortality&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(DR)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Concentration        Instar         Block        Rep           Total           Pupae           %Pupated          Day0           Day1p            Day2p            Day3p            Day4p             Day5p            Day6p            Day7p            Day8p            Day9p            Day10p           Day11p           Day12p           Day13p           Day14p      
##  Min.   :0.0000   Min.   :1.00   Min.   :1   Min.   :1.00   Min.   :10.00   Min.   : 0.000   Min.   :0.000   Min.   :10.00   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.00000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  
##  1st Qu.:0.1000   1st Qu.:1.75   1st Qu.:1   1st Qu.:1.75   1st Qu.:10.00   1st Qu.: 0.000   1st Qu.:0.000   1st Qu.:10.00   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.08333   1st Qu.:0.1000   1st Qu.:0.1000   1st Qu.:0.1000   1st Qu.:0.1000   1st Qu.:0.1000   1st Qu.:0.1000   1st Qu.:0.1404   1st Qu.:0.1404   1st Qu.:0.4000   1st Qu.:0.4000  
##  Median :0.3750   Median :2.50   Median :2   Median :2.50   Median :10.00   Median : 0.000   Median :0.000   Median :10.00   Median :0.3000   Median :0.6500   Median :0.7500   Median :0.80000   Median :0.8500   Median :0.9000   Median :0.9000   Median :1.0000   Median :1.0000   Median :1.0000   Median :1.0000   Median :1.0000   Median :1.0000   Median :1.0000  
##  Mean   :0.4333   Mean   :2.50   Mean   :2   Mean   :2.50   Mean   :10.17   Mean   : 3.615   Mean   :0.346   Mean   :10.17   Mean   :0.3924   Mean   :0.5186   Mean   :0.5499   Mean   :0.56945   Mean   :0.5846   Mean   :0.6026   Mean   :0.6179   Mean   :0.6258   Mean   :0.6367   Mean   :0.6425   Mean   :0.6745   Mean   :0.6778   Mean   :0.7434   Mean   :0.7454  
##  3rd Qu.:0.7500   3rd Qu.:3.25   3rd Qu.:3   3rd Qu.:3.25   3rd Qu.:10.00   3rd Qu.: 9.000   3rd Qu.:0.900   3rd Qu.:10.00   3rd Qu.:0.8000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.00000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  
##  Max.   :1.0000   Max.   :4.00   Max.   :3   Max.   :4.00   Max.   :14.00   Max.   :14.000   Max.   :1.000   Max.   :14.00   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.00000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;op &amp;lt;- par(mfrow = c(1, 2), mar=c(3.2,3.2,2,.5), mgp=c(2,.7,0)) 
plot(DR$Day2p ~ DR$Concentration, data = DR, main=&amp;quot;Original Dose Scale&amp;quot;)
plot(DR$Day2p ~ logit(DR$Concentration+0.01), data = DR, main=&amp;quot;Logarithmic Dose Scale&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/DR%20mortality%20Data-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Look at control data, make sure mortality is &amp;lt; ~ 5%
aggregate(DR[,10], list(DR$Concentration), mean)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Group.1      Day2p
## 1    0.00 0.02500000
## 2    0.10 0.02689394
## 3    0.25 0.18882576
## 4    0.50 0.90416667
## 5    0.75 0.98541667
## 6    1.00 0.98125000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Option 1: Dose Response Curve&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#option 1: use DR
Day2DR&amp;lt;-drm(DR$Day2p ~ (DR$Concentration), DR$Instar, data = DR, fct=LL.2(names=c(&amp;quot;Slope&amp;quot;, &amp;quot;LD50&amp;quot;)), type=(&amp;quot;binomial&amp;quot;), na.action=na.omit)
summary(Day2DR)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Model fitted: Log-logistic (ED50 as parameter) with lower limit at 0 and upper limit at 1 (2 parms)
## 
## Parameter estimates:
## 
##          Estimate Std. Error t-value   p-value    
## Slope:1 -4.275095   1.136144 -3.7628 0.0001680 ***
## Slope:2 -3.852419   0.963761 -3.9973 6.408e-05 ***
## Slope:3 -5.163489   1.361471 -3.7926 0.0001491 ***
## Slope:4 -4.556448   1.151696 -3.9563 7.612e-05 ***
## LD50:1   0.299385   0.035025  8.5478 &amp;lt; 2.2e-16 ***
## LD50:2   0.317748   0.039065  8.1339 4.299e-16 ***
## LD50:3   0.333927   0.036185  9.2284 &amp;lt; 2.2e-16 ***
## LD50:4   0.347131   0.039313  8.8299 &amp;lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#shows slope, LD50 is significantly different than 0 for each instar
par(mfrow = c(1, 1), mar=c(3.2,3.2,.5,.5), mgp=c(2,.7,0))
plot(Day2DR, broken=TRUE, xlim=c(0,2), bty=&amp;quot;l&amp;quot;, xlab=&amp;quot;Concentration&amp;quot;, ylab=&amp;quot;Mortality&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/DRC%20mortality-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;EDcomp(Day2DR,c(50,50), reverse=TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Estimated ratios of effect doses
## 
##           Estimate Std. Error t-value p-value
## 2/1:50/50  1.06134    0.18012 0.34053 0.73345
## 3/1:50/50  1.11538    0.17786 0.64870 0.51653
## 4/1:50/50  1.15948    0.18879 0.84473 0.39826
## 3/2:50/50  1.05092    0.17223 0.29566 0.76749
## 4/2:50/50  1.09247    0.18261 0.50639 0.61259
## 4/3:50/50  1.03954    0.16294 0.24266 0.80827&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Instar has little effect on mortality, instars 1 and 2 similar, 3 and 4 less responsive. Overall, model doesn&amp;#39;t fit well.

#look at residuals
op &amp;lt;- par(mfrow = c(1, 2), mar=c(3.2,3.2,2,.5), mgp=c(2,.7,0))
plot(residuals(Day2DR) ~ fitted(Day2DR), main=&amp;quot;Residuals vs Fitted&amp;quot;)
qqnorm(residuals(Day2DR))
qqline(residuals(Day2DR)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/DRC%20mortality-2.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#data not normally distributed

op &amp;lt;- par(mfrow = c(1, 2), mar=c(3.2,3.2,.5,.5), mgp=c(2,.7,0))
plot(Day2DR, broken=TRUE, bty=&amp;quot;l&amp;quot;, xlab=&amp;quot;Conc&amp;quot;, ylab=&amp;quot;Mortality&amp;quot;)
modelFit(Day2DR)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Goodness-of-fit test
## 
##              Df Chisq value p value
##                                    
## DRC model   232      71.717       1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#model doesn&amp;#39;t fit very well, instar doesnt have much effect on DR&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/DRC%20mortality-3.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Option 2: Linear Model&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Option 2: look at linear model
pairs(DR$Day2p ~ (DR$Block) + (DR$Rep) + DR$Concentration + DR$Instar)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/DR%20LM%20mortality-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;op &amp;lt;- par(mfrow = c(1, 1), mar=c(3.2,3.2,0,.5), mgp=c(2,.7,0))
plot(DR$Day2p ~ DR$Concentration, data = DR, bty=&amp;quot;l&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/DR%20LM%20mortality-2.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;day2.lm &amp;lt;- lm(DR$Day2p ~ (Block) + (Rep) + Concentration + Instar + Concentration:Instar, data = DR)
summary(day2.lm)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = DR$Day2p ~ (Block) + (Rep) + Concentration + Instar + 
##     Concentration:Instar, data = DR)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.35969 -0.16212 -0.02192  0.11120  0.47196 
## 
## Coefficients:
##                       Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)           0.061467   0.057127   1.076    0.283    
## Block                 0.007197   0.013744   0.524    0.601    
## Rep                  -0.001654   0.010037  -0.165    0.869    
## Concentration         1.112013   0.077320  14.382   &amp;lt;2e-16 ***
## Instar               -0.021014   0.015825  -1.328    0.185    
## Concentration:Instar  0.016180   0.028233   0.573    0.567    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.1904 on 282 degrees of freedom
## Multiple R-squared:  0.8257, Adjusted R-squared:  0.8226 
## F-statistic: 267.1 on 5 and 282 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(day2.lm, which=1, bty=&amp;quot;l&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/DR%20LM%20mortality-3.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#look at residuals
plot(residuals(day2.lm) ~ fitted(day2.lm), main=&amp;quot;Residuals vs Fitted&amp;quot;)
abline(h=0) #should look random&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/DR%20LM%20mortality-4.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;qqnorm(residuals(day2.lm))
qqline(residuals(day2.lm)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/DR%20LM%20mortality-5.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# fit with binomial dist
day2.lm2 &amp;lt;- glm((DR$Day2p)~ (DR$Block) + (DR$Rep) + (DR$Concentration) + (DR$Instar) + (DR$Concentration:DR$Instar), family = binomial(link = &amp;quot;logit&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in eval(family$initialize): non-integer #successes in a binomial glm!&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(day2.lm2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## glm(formula = (DR$Day2p) ~ (DR$Block) + (DR$Rep) + (DR$Concentration) + 
##     (DR$Instar) + (DR$Concentration:DR$Instar), family = binomial(link = &amp;quot;logit&amp;quot;))
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.4176  -0.2332   0.0301   0.1454   1.3145  
## 
## Coefficients:
##                            Estimate Std. Error z value Pr(&amp;gt;|z|)    
## (Intercept)                 -3.6102     1.4276  -2.529 0.011443 *  
## DR$Block                     0.1167     0.2910   0.401 0.688496    
## DR$Rep                      -0.0268     0.2122  -0.126 0.899487    
## DR$Concentration            11.1180     3.3689   3.300 0.000966 ***
## DR$Instar                   -0.3291     0.4657  -0.707 0.479807    
## DR$Concentration:DR$Instar   0.3105     1.2578   0.247 0.805051    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 313.890  on 287  degrees of freedom
## Residual deviance:  37.273  on 282  degrees of freedom
## AIC: 61.664
## 
## Number of Fisher Scoring iterations: 7&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(day2.lm2, which=1, bty=&amp;quot;l&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/DR%20LM%20mortality-6.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(residuals(day2.lm2) ~ fitted(day2.lm2), main=&amp;quot;Residuals vs Fitted&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/DR%20LM%20mortality-7.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;qqnorm(residuals(day2.lm2))
qqline(residuals(day2.lm2)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mosquito_dose_response_files/figure-html/DR%20LM%20mortality-8.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#compare linear model with DR, linear &amp;gt; DR due to lower AIC
AIC(Day2DR, day2.lm, day2.lm2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          df        AIC
## Day2DR    8  189.95387
## day2.lm   7 -129.99081
## day2.lm2  6   61.66438&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Resources and references</title>
      <link>/post/resources_and_references/</link>
      <pubDate>Thu, 01 Aug 2019 21:07:04 -0500</pubDate>
      
      <guid>/post/resources_and_references/</guid>
      <description>


&lt;p&gt;Here are some useful online references that related to topics discussed during the workshop.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Modeling&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www3.nd.edu/~steve/Rcourse/Lecture7v1.pdf&#34; class=&#34;uri&#34;&gt;https://www3.nd.edu/~steve/Rcourse/Lecture7v1.pdf&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://tutorials.iq.harvard.edu/R/Rstatistics/Rstatistics.html&#34; class=&#34;uri&#34;&gt;https://tutorials.iq.harvard.edu/R/Rstatistics/Rstatistics.html&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.statslab.cam.ac.uk/~pat/redwsheets.pdf&#34; class=&#34;uri&#34;&gt;http://www.statslab.cam.ac.uk/~pat/redwsheets.pdf&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;tidyverse&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.tidyverse.org/&#34; class=&#34;uri&#34;&gt;https://www.tidyverse.org/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://r4ds.had.co.nz/&#34; class=&#34;uri&#34;&gt;http://r4ds.had.co.nz/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://jrnold.github.io/r4ds-exercise-solutions/&#34; class=&#34;uri&#34;&gt;https://jrnold.github.io/r4ds-exercise-solutions/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Correlation and Regression&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.statmethods.net/stats/regression.html&#34; class=&#34;uri&#34;&gt;https://www.statmethods.net/stats/regression.html&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://rcompanion.org/handbook/F_12.html&#34; class=&#34;uri&#34;&gt;http://rcompanion.org/handbook/F_12.html&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Multiple regression&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.statmethods.net/stats/regression.html&#34; class=&#34;uri&#34;&gt;http://www.statmethods.net/stats/regression.html&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://ww2.coastal.edu/kingw/statistics/R-tutorials/multregr.html&#34; class=&#34;uri&#34;&gt;http://ww2.coastal.edu/kingw/statistics/R-tutorials/multregr.html&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.r-bloggers.com/r-tutorial-series-multiple-linear-regression/&#34; class=&#34;uri&#34;&gt;http://www.r-bloggers.com/r-tutorial-series-multiple-linear-regression/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://newonlinecourses.science.psu.edu/stat501/node/283/&#34; class=&#34;uri&#34;&gt;https://newonlinecourses.science.psu.edu/stat501/node/283/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Nonlinear regression&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.jstatsoft.org/article/view/v066i05/v66i05.pdf&#34; class=&#34;uri&#34;&gt;https://www.jstatsoft.org/article/view/v066i05/v66i05.pdf&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.apsnet.org/edcenter/advanced/topics/EcologyAndEpidemiologyInR/DiseaseProgress/Pages/NonlinearRegression.aspx&#34; class=&#34;uri&#34;&gt;http://www.apsnet.org/edcenter/advanced/topics/EcologyAndEpidemiologyInR/DiseaseProgress/Pages/NonlinearRegression.aspx&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Books and other articles&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Nonlinear Regression with R: &lt;a href=&#34;https://www.springer.com/la/book/9780387096155&#34; class=&#34;uri&#34;&gt;https://www.springer.com/la/book/9780387096155&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Extending the Linear Model with R: &lt;a href=&#34;https://www.crcpress.com/Extending-the-Linear-Model-with-R-Generalized-Linear-Mixed-Effects-and/Faraway/p/book/9781498720960&#34; class=&#34;uri&#34;&gt;https://www.crcpress.com/Extending-the-Linear-Model-with-R-Generalized-Linear-Mixed-Effects-and/Faraway/p/book/9781498720960&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
